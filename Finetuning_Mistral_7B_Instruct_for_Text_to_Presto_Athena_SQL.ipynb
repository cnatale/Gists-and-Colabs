{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnatale/Gists-and-Colabs/blob/main/Finetuning_Mistral_7B_Instruct_for_Text_to_Presto_Athena_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2SbdFfHXL6z"
      },
      "source": [
        "Note: this notebook requires a GPU instance with at minimum 40GB of VRAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEkm_Q9AGgTX"
      },
      "source": [
        "### Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "64NqOtHUtL7U"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda do_setlocale=True: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IovaXt4ZJQ_",
        "outputId": "f30f7ab5-317f-4aa1-d4f0-edfcaddd179b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m439.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers trl accelerate torch bitsandbytes peft datasets -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck_5U-vIq7zW"
      },
      "source": [
        "#### Load Local Dataset\n",
        "\n",
        "I've pre-processed the Spider and WikiSQL datasets. Load them into memory as a HuggingFace Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO63aFsdMdlq",
        "outputId": "23256fcd-2fc1-4622-8804-69f483805a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-03 13:59:09--  https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql/resolve/main/train_randomized.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.55, 13.33.33.20, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1828018 (1.7M) [text/plain]\n",
            "Saving to: ‘training_data/train.jsonl’\n",
            "\n",
            "training_data/train 100%[===================>]   1.74M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-01-03 13:59:10 (44.2 MB/s) - ‘training_data/train.jsonl’ saved [1828018/1828018]\n",
            "\n",
            "--2024-01-03 13:59:10--  https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql/resolve/main/valid_randomized.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.55, 13.33.33.110, 13.33.33.102, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 266088 (260K) [text/plain]\n",
            "Saving to: ‘training_data/valid.jsonl’\n",
            "\n",
            "training_data/valid 100%[===================>] 259.85K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-03 13:59:10 (45.8 MB/s) - ‘training_data/valid.jsonl’ saved [266088/266088]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the training + validation data from Huffingface repo\n",
        "\n",
        "!mkdir -p training_data\n",
        "!wget https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql/resolve/main/train_randomized.jsonl -O training_data/train.jsonl\n",
        "!wget https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql/resolve/main/valid_randomized.jsonl -O training_data/valid.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DI1G_zS8PWh9"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def read_jsonl(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            json_data = json.loads(line.strip())\n",
        "            data.append(json_data)\n",
        "    return data\n",
        "\n",
        "# Read the train and validation files\n",
        "train_data = read_jsonl('training_data/train.jsonl')\n",
        "valid_data = read_jsonl('training_data/valid.jsonl')\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "train_df = pd.DataFrame(train_data)\n",
        "valid_df = pd.DataFrame(valid_data)\n",
        "\n",
        "# Convert DataFrame to Huggingface Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "valid_dataset = Dataset.from_pandas(valid_df)\n",
        "\n",
        "# Example of processing\n",
        "# train_texts = [example['text'] for example in train_dataset]\n",
        "# valid_texts = [example['text'] for example in valid_dataset]\n",
        "\n",
        "instruct_tune_dataset = {\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": valid_dataset\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmAvZLhkrY6p"
      },
      "source": [
        "#### Data structure\n",
        "\n",
        "The dataset contains three different columns. We are only interested in the columns `prompt` and `response`. There are 9 different possible source value in the `source` column. We are only interested in one of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfDpPbAyTHff",
        "outputId": "dd85c7e9-304d-47e1-d278-7fbec4ff2b4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Find the id and city of the student address with the highest average monthly rental.\\nAdditional table information: table: behavior_monitoring',\n",
              " 'answer': 'SELECT T2.address_id, T1.city FROM Addresses AS T1 JOIN Student_Addresses AS T2 ON T1.address_id = T2.address_id GROUP BY T2.address_id ORDER BY AVG(monthly_rental) DESC LIMIT 1'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "instruct_tune_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNKsQDzlilSi"
      },
      "source": [
        "We will use just a small subset of the data for this training example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d-fQF_ZngrHx"
      },
      "outputs": [],
      "source": [
        "instruct_tune_dataset[\"train\"] = instruct_tune_dataset[\"train\"].select(range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L14C9wIxg_V6"
      },
      "outputs": [],
      "source": [
        "instruct_tune_dataset[\"test\"] = instruct_tune_dataset[\"test\"].select(range(200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z22tW4bYhEr1",
        "outputId": "bef6ab7b-0aca-479a-d4c0-78ec8d8a97e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': Dataset({\n",
              "     features: ['question', 'answer'],\n",
              "     num_rows: 1000\n",
              " }),\n",
              " 'test': Dataset({\n",
              "     features: ['question', 'answer'],\n",
              "     num_rows: 200\n",
              " })}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "instruct_tune_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQy1Xv7Mr7EN"
      },
      "source": [
        "#### Create Formatted Prompt\n",
        "\n",
        "In the following function we'll be merging our `prompt` and `response` columns by creating the following template:\n",
        "\n",
        "```\n",
        "<s>[INST] Write a SQL query or use a function to answer the following question. Use the SQL dialect Presto for AWS Athena.\\n\\nWhat is the average age of the dogs who have gone through any treatments?\\nAdditional table information: table: dog_kennels [/INST] SELECT AVG(age) FROM Dogs WHERE dog_id IN (SELECT dog_id FROM Treatments)</s>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZYLl8EJmTRL2"
      },
      "outputs": [],
      "source": [
        "def create_prompt(sample):\n",
        "  \"\"\"\n",
        "  Update the prompt template:\n",
        "  Combine both the prompt and input into a single column.\n",
        "\n",
        "  \"\"\"\n",
        "  bos_token = \"<s>\"\n",
        "  original_system_message = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "  system_message = \"Write a SQL query or use a function to answer the following question. Use the SQL dialect Presto for AWS Athena.\"\n",
        "  question = sample[\"question\"].replace(original_system_message, \"\").strip()\n",
        "  response = sample[\"answer\"].strip()\n",
        "  eos_token = \"</s>\"\n",
        "\n",
        "  full_prompt = \"\"\n",
        "  full_prompt += bos_token\n",
        "  full_prompt += \"[INST] <<SYS>>\" + system_message + \"<</SYS>>\\n\\n\"\n",
        "  full_prompt += question + \" [/INST] \"\n",
        "  full_prompt += response\n",
        "  full_prompt += eos_token\n",
        "\n",
        "  return full_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "cdi5goqbfFOK",
        "outputId": "f29ddcf1-806e-465e-9649-84a78ba08961"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] <<SYS>>Write a SQL query or use a function to answer the following question. Use the SQL dialect Presto for AWS Athena.<</SYS>>\\n\\nWhat is the average age of the dogs who have gone through any treatments?\\nAdditional table information: table: dog_kennels [/INST] SELECT AVG(age) FROM Dogs WHERE dog_id IN (SELECT dog_id FROM Treatments)</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "create_prompt(instruct_tune_dataset[\"test\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4TZODFA8gy9"
      },
      "source": [
        "### Map the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y7dAhU6e8e3d"
      },
      "outputs": [],
      "source": [
        "# Apply the map function to each dataset - Don't actually do this because it is handled in SFTTrainer invocation with the create_prompt param\n",
        "# instruct_tune_dataset[\"train\"] = instruct_tune_dataset[\"train\"].map(create_prompt)\n",
        "# instruct_tune_dataset[\"test\"] = instruct_tune_dataset[\"test\"].map(create_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qjy9PYUaY3W"
      },
      "source": [
        "### Loading the Base Model\n",
        "\n",
        "Load the model in `4bit`, with double quantization, with `bfloat16` as the compute dtype.\n",
        "\n",
        "In this case we are using the instruct-tuned model - instead of the base model. For fine-tuning a base model will need a lot more data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qRb5keMJB7wr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "e70b1302aab144f7ab96fcb34971d12c",
            "866b924c027a424cb80121a1b4f80492",
            "d161ac90d05f4e5d919891792d0828ae",
            "014c26b833bf4fa9ba3e7ee3c4e0019a",
            "85554c32a6ff4a069738f24a211a6df0",
            "09cd4ef57a4a4d91a204cd011a7f864f",
            "61ee99a881c5442595642b74fd4ee422",
            "e938d2df461d4d2483e484f0a188a56e",
            "4927f0b8bf6e4525addeaceb8655646d",
            "8a76be851ab6474792f693eec0947918",
            "9cec362568574caf8a5a8f001a9a3b30",
            "6d2d211782c9457798449bb368e6c275",
            "cd12842e5dc14267a8ec87792634a1d3",
            "134f5a2265db4db19d122d6d2c4ce724",
            "189b6a15eafc4205ba8385bb79ff08a1",
            "01ee37a1c72b4b688a955883559f2137",
            "eefba4a309654b72b3285720972de680",
            "ad3f9f71803842dc9b4070680333d2e8",
            "97c289a1b73e46638b0ec8117d8ba1e3",
            "7a1bdad953a24f00a2e7947101b53956",
            "8a306d206c7642dc8e51d46f90b4f175",
            "ce6b4663f37644608966321a26825cda",
            "7cab55a554934725b51fdb60c4c0b7ed",
            "311360687583488cb6e6f2413c1ae049",
            "70764efc1bbe4e34add35c38233cad1c",
            "905a803b0b8e44ba8c234c4e3aa1c780",
            "938726d0e31243729fc2bc0f75604ec2",
            "05f8620285c142a190506e04fc0dcb80",
            "18aa55e8f37a482dbc43edb914797182",
            "e8d818d0aeec4be49873338839241009",
            "ab7b10ec23ff479ebb596f53fd73fa37",
            "76316258bcea4be5ab7c10f38038dd16",
            "d985ab4d975340949a8690356c1dc243",
            "8d23defd27084214898658795be1f450",
            "b6b7ed0059654452be8bf5a8626778f0",
            "2209a7f84d60462fb9fa1144acf8b8d2",
            "077d0a67cb7b47e9be158aa38bbd6ee0",
            "9a39311c15bc435d93b081e63aa39652",
            "e2f7da26c89d432b98f42c3426a6cc77",
            "983358eefd614b0d9fd31239fef0a8bb",
            "74cd52bd619f43ac8a9925d65db73972",
            "1bbea4dddf424dce9073ac74a8aa8ec9",
            "976d97b691e840cfac5f2f3082b3bff6",
            "07f2defc66904794862bfbc187b5523b",
            "265a6ad4eb3e4a3abcbace301fbfc34d",
            "cbe824f72d884abdb76b1ea9830336f1",
            "f98996c3b7f143ada87f131976729671",
            "625725ccccbf40eca0ca19932fafab73",
            "7c54081abe084e19a00ee2d27cb1263f",
            "120621624ea24bd8ad90b4b61ca04996",
            "23135116651a4837acbb7a6e7b695138",
            "9071e09a0f894e51aaa10f13d48588b2",
            "4b7c8f2aed004d31b522aefb98cd4908",
            "800b05732b9641bcbc8f57b4a8482533",
            "1a2b239f554540538be74942753f68cb",
            "50a7bea1ad494e0d8b6f07a9579714ce",
            "4a653f8785e44991a026801552e05184",
            "b949027763e74760ae404174555935ca",
            "5380c19b9c5e40e58b148ed0285d2392",
            "e1afdce4ce7b48e28b3e1f523013a0de",
            "d53f2e53db1c483bac9e0a34474f8eee",
            "187a28b3e7d7448188fb99d2e498557c",
            "90e27803643e4dfcb30a8fcd33b09fc0",
            "38b316b3410543d68da6bb0b116c668e",
            "f7c377a9f602464db43d1b77e8a15b93",
            "0a5eb6383dd64cbd835a5f929ae2281f",
            "021ebaef9442472ba194111a7ee3d5ae",
            "c23975e7c26c428f898ea37620385115",
            "030ede6922444f2792338d5ea7d61353",
            "b152fe67d4c64b4bb44a73e2f7b60015",
            "da58d221ad2a4abfa45cc939b5b172de",
            "f44a6c7ff92346bcaf94c3e86eef8b18",
            "6115486214ef4ee5906edf66b71c4ea0",
            "552875444ea44269b6889f9dc2d6cfb1",
            "59ad2204d5d54a91b4854b3b2717ad81",
            "787509e5e266450284f7fc7b03789ef5",
            "22091f7b2147426eadc10f37e476e1e9"
          ]
        },
        "id": "ZbaaN_VdWABp",
        "outputId": "d90b3f10-a6c7-482e-cd11-4ef3e563be3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e70b1302aab144f7ab96fcb34971d12c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d2d211782c9457798449bb368e6c275"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cab55a554934725b51fdb60c4c0b7ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d23defd27084214898658795be1f450"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "265a6ad4eb3e4a3abcbace301fbfc34d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50a7bea1ad494e0d8b6f07a9579714ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "021ebaef9442472ba194111a7ee3d5ae"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    device_map='auto',\n",
        "    quantization_config=nf4_config,\n",
        "    use_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9TzTWLD2WBZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "c669614659d04c2894e824fd49961cee",
            "8d204bb0312840d3928fb2f356b7b91a",
            "2db7150b727c49a39c17e04b216301a4",
            "7ab64ae1b91e4399b03a7cd00e9c5b1a",
            "1599555d51ca47569e0d0429d49835d5",
            "cd526a33f4944edebe374a209dc46058",
            "b5552b6f5d8b4c848a18a45e250d18e6",
            "320e6e8e37bf4a4099b1b29d7c9abc00",
            "7ad24fcf04ea43cf92abb65122a50a9b",
            "dd075c4872bb46729042d9d8348aed44",
            "b1744365faaa43e8b8b314e5eff92a3e",
            "fcf27688620a409e96b3fc70e4333b67",
            "5338e56f80624d3ab68ae00688248ffa",
            "7374d314be41468dbf7e4f2c5d1b4df4",
            "190666a9dcbd49abad6b718d132c250e",
            "a817134b3ee14bee8d7c24955eb45b8b",
            "bbec8cb9c50c4ce3b7bd2a341f8fe399",
            "3324620a2adb4c3ba4e7424ce9379bd2",
            "1f7d1f8d05b34e1dac861156dd8ed64c",
            "540cf369d08a46ecbe7d691f9040fdfb",
            "0b6144cca3c24d6c96b0a086669a4bdc",
            "9da8ac8bc08d4060b2c367c12f7e516b",
            "543d2a87aa6f4d8e980181bce1c16a9e",
            "848ec03bd6294447a1e36466c6ad789c",
            "b35775c1be574210b9472fc345d0d664",
            "03f62897007e4c0aa6e717d17e52bf4b",
            "243e1b951a994f91983541355419f48d",
            "b11cbf4af017404098a8846c4f79f0d1",
            "a021fa1b81ca430fad820f2a4e08b710",
            "c04c690f4a454051912631fc7804984d",
            "78d31f0488b740e9a8cad25b96fdbdbe",
            "dda502f1258e4d3dbaf47cd99c30c537",
            "35f7cee0dd2449aa9fc90a2bb217a75b",
            "953540da952e438f9e4b850dc273a2b8",
            "41ffc19e8560408fa1e3099a935dcc41",
            "d1b32e95244947099eab436ef464fc1d",
            "472b81b371504e1bb58701dc2f548de0",
            "5b887f3ffef643b98070272f2d4b8027",
            "09e43cfa6f6f4b0db65287db96e93729",
            "3a455bca1b1947f6916cef15251514b4",
            "db2907ecb0fe4e8b9564b613879e0f4e",
            "eb5b769fb705496db5c9a0bfd1e879a4",
            "895ec8f38eb74ceb85ab6212c8db2d17",
            "086facd8ce024efbae38543a66573a6e"
          ]
        },
        "outputId": "8e15e2f5-a7cd-4beb-ab26-1b21487c0136"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c669614659d04c2894e824fd49961cee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcf27688620a409e96b3fc70e4333b67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "543d2a87aa6f4d8e980181bce1c16a9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "953540da952e438f9e4b850dc273a2b8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# print the tokenizer function\n",
        "# print(tokenizer.default_chat_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlQxPyiKi51k"
      },
      "source": [
        "Check the performance of the pre-fine-tuned model at the task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wRWhXzXrc41b"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt, model):\n",
        "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "  model_inputs = encoded_input.to('cuda')\n",
        "\n",
        "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  return decoded_output[0].replace(prompt, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p1q6rxvU61hO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "77ce3273-212c-4bd5-9199-9fb520e867ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s><s> [INST] Write a SQL query or use a function to answer the following question. Use the SQL dialect Presto for AWS Athena.\\n\\nWhat is the average age of the dogs who have gone through any treatments? [/INST] The following SQL query can be used to answer the question:\\n```\\nSELECT AVG(Age)\\nFROM Dogs\\nWHERE HasTreated = 'Yes';\\n```\\nNote: This assumes that there is a column named `Age` and another column named `HasTreated` in the `Dogs` table in the Presto database on AWS Athena.</s>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "prompt=\"<s>[INST] Write a SQL query or use a function to answer the following question. Use the SQL dialect Presto for AWS Athena.\\n\\nWhat is the average age of the dogs who have gone through any treatments? [/INST]\"\n",
        "generate_response(prompt, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Vs5Dc3DdY_"
      },
      "source": [
        "### Setting up the Training\n",
        "Training uses the `huggingface` and the `peft` libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SQulqDzjd0gD"
      },
      "outputs": [],
      "source": [
        "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SWl1MgjDrXX"
      },
      "source": [
        "we need to prepare the model to be trained in 4bit so we will use the  `prepare_model_for_kbit_training` function from peft\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bcco3ITVd486"
      },
      "outputs": [],
      "source": [
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go8_nVq7jO9d"
      },
      "source": [
        "### Hyper-parameters for training\n",
        "These parameters will depend on how long you want to run training for.\n",
        "Most important to consider:\n",
        "\n",
        "`num_train_epochs/max_steps`: How many iterations over the data you want. Too high of a ratio leads to overfitting.\n",
        "\n",
        "`learning_rate`: Controls the speed of convergence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YhoCjs9md8pB"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "modelname = \"Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "  output_dir = modelname,\n",
        "  #num_train_epochs=5,\n",
        "  max_steps = 80, # comment out this line if you want to train in epochs\n",
        "  per_device_train_batch_size = 4,\n",
        "  warmup_steps = 0.03,\n",
        "  logging_steps=10,\n",
        "  save_strategy=\"epoch\",\n",
        "  #evaluation_strategy=\"epoch\",\n",
        "  evaluation_strategy=\"steps\",\n",
        "  eval_steps=10, # comment out this line if you want to evaluate at the end of each epoch\n",
        "  learning_rate=1e-4,\n",
        "  fp16=True,\n",
        "  lr_scheduler_type='constant',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz6Vhh4WFpMM"
      },
      "source": [
        "Setting up the trainer.\n",
        "\n",
        "`max_seq_length`: Context window size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UyyNtDrmeAkc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "181683e6d38e4e0192520cc06cbdf62e",
            "853a60025b3c492d9fef418633700a51",
            "f687e7df7b83406cbe225d3428504277",
            "d46e14d875f54077b575bad03fefb5ce",
            "159de2582d0d4056b7fa0ae435e01c40",
            "96d84cef1bbb42b3b9cfede246c24069",
            "cf139ff385de42c2a7504415b699cf06",
            "d5b7f1c2f8a34f58a3c63e8d645de72a",
            "4e2bf65e77064b05b117fa51e86b3361",
            "6e8806ad1587495e9b75b0392c8e16e2",
            "89d970868c8f4edcb90a54e853e99879",
            "29e055fe95464b94b11a2069bfb238c9",
            "0fd8d8de0ed840a481346d2741292871",
            "b40a0bca20024a0ab977dfc4f142b06f",
            "49eb3e296e88478d8ae7f52a95e83f66",
            "91e47a895c214f6a960d0519644f2ca7",
            "ebedcb910ecc4b2fae8d6afa60072374",
            "e156eeb5033f41f3b8c149cc4134a673",
            "21d949f2871e4a78b23efb7582860810",
            "dbea0d84ca0d4e9b89f979b6700ed56a",
            "e45aa988330841449ebabf953142b0d3",
            "3aa645e791984f8f9691e30b122a1b37"
          ]
        },
        "outputId": "4f3aa595-69f4-46c0-f106-b4e88d2c9281"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "181683e6d38e4e0192520cc06cbdf62e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29e055fe95464b94b11a2069bfb238c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:302: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "max_seq_length = 2048\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "  model=model,\n",
        "  peft_config=peft_config,\n",
        "  max_seq_length=max_seq_length,\n",
        "  tokenizer=tokenizer,\n",
        "  packing=True,\n",
        "  formatting_func=create_prompt, # this will apply the create_prompt mapping to all training and test dataset\n",
        "  args=args,\n",
        "  train_dataset=instruct_tune_dataset[\"train\"],\n",
        "  eval_dataset=instruct_tune_dataset[\"test\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rQpQVihs6jD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c36ec37b-054d-47d1-d2d3-2fd4fe3d42d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan  3 14:00:57 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0              64W / 400W |   6643MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bsOO4bR9fQBb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "a0372565-c4ad-4026-832f-2a3ece370651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 06:26, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.362800</td>\n",
              "      <td>1.109636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.041100</td>\n",
              "      <td>0.893801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.867800</td>\n",
              "      <td>0.780792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.768100</td>\n",
              "      <td>0.727106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.710800</td>\n",
              "      <td>0.685231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.652100</td>\n",
              "      <td>0.657275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.618000</td>\n",
              "      <td>0.648421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.582400</td>\n",
              "      <td>0.647070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=80, training_loss=0.8253897905349732, metrics={'train_runtime': 391.4091, 'train_samples_per_second': 0.818, 'train_steps_per_second': 0.204, 'total_flos': 2.675179360616448e+16, 'train_loss': 0.8253897905349732, 'epoch': 5.71})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ysHgWnwbfRSt"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"mistral_7b_instruct_v0_1_txt_2_sql\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na6xC6f-mGGm"
      },
      "source": [
        "# Save Model and Push to Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SBPVlNe0j-Nk"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface-hub -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N6OzYqHRHoPg"
      },
      "outputs": [],
      "source": [
        "# Set the HuggingFace token as an environment variable\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjS8AfX7ipjt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NGtL69WVEIbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c43c8a-0d1d-4603-d4eb-72c534102062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# I switched to this login method because the notebook_login() method\n",
        "# below stopped working after a HuggingfaceHub update\n",
        "!huggingface-cli login --token $HF_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uCDmkWCXnmuv"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPeqMfJUKRoB"
      },
      "source": [
        "Push the LoRA only to the hub. See below for merging the LoRA back into the main model itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HJTZaSXqnqPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "e8e07c8ee05e4dbb845465f81354a0af",
            "3cc85ddcb1cf4b7f8a521b659b3edafa",
            "5b68382b43b9493e834e49b649306973",
            "4a234f02255a444fa577eb9ce1448693",
            "87ee67023e8748cd9b72597d97952273",
            "4fe270cf7c394a9dbc0a7719d03e351d",
            "930ce1f7c325475e8102bffdce731846",
            "9e7c65d0d8f64a4d8090273ec08781c5",
            "9ed71ab49fa1425c853d81b4a4e9b74f",
            "3fc67fb319274756aa2068f7ab7fb3f4",
            "a993c04f5cc145f1b5fb07845e40c5d8",
            "a49aaa3697764d0680c057d27b1a8ac1",
            "b5d10d7f371e48b99b259e9da62e3ed4",
            "0411e6dcd9cb4c69868861e2186e96c7",
            "975d87c56d41432c8e1ce13353bf54be",
            "2fc28c9ebae34f29b3da7c3100c7723d",
            "d8bd5efa67da44cabc288f4574d8b2d1",
            "1dfcdfb4cc804a499f00d80e95826160",
            "27da06ddc80544638322d46db3be4b57",
            "9e1431a5df314bda84e087701a1723c5",
            "39d195e8327f421db3d6cd6706a024c1",
            "27b314c10859481e84f6fdc30567f61b",
            "ea64fc1482244ddf80a29937e335daae",
            "16b822fa526741e39acb1cb491fdfaad",
            "d2c8f13c97c742b1953e7a28b22b15ea",
            "b3cebafe39254a6cacd6003f5db18ab4",
            "38eedbeac0dc47a8826b057b472f12ef",
            "bc19405223854c7f9951fadf7fa12a67",
            "f12c5442ba4e4fd5bd27b07f6de624db",
            "4fbe888e126a4b78a0c78f462eca42ad",
            "232d939324984400a31424658ae071f2",
            "262dfb1016664afdba79945aee4756b4",
            "a548e7ffdc3a430fb7bbce18ec0e56c9",
            "b571bb8cfd8848d086e41c6bf305bf9e",
            "4db84a5e41ed4812a36198d694a4707d",
            "aad1958ca48f4f4ab524de70fde62789",
            "47fa38ac51c6478290ca5cea27d17c65",
            "ae6ffcc365c44dac923f1a5be4a3c4a0",
            "4f71cd9286b7492f9b7dc097bdcdf54f",
            "1d1ad6c4193b45c7bbb75409754898bf",
            "d3f2f46148814368aaa10e125443be2e",
            "f25daa9e246d44e1929070c3df3730d8",
            "ec70ebbea65b49c8b05b0beee9d007b3",
            "6d6b7cc546a1409fb96326df24caab32"
          ]
        },
        "outputId": "a5ef6be6-5bfd-4399-a191-987883fd0d0c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "events.out.tfevents.1704290457.4f0560a2c54d.546.0:   0%|          | 0.00/8.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8e07c8ee05e4dbb845465f81354a0af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a49aaa3697764d0680c057d27b1a8ac1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea64fc1482244ddf80a29937e335daae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b571bb8cfd8848d086e41c6bf305bf9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/cnatale/Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/commit/1adf9e6e324056c588d8386d7745c32aa82e21fe', commit_message='cnatale/Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL', commit_description='', oid='1adf9e6e324056c588d8386d7745c32aa82e21fe', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "new_model_id = f\"cnatale/{modelname}\"\n",
        "trainer.push_to_hub(new_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Uvn0wbykGKl"
      },
      "source": [
        "Push the merged model to HuggingFace, along with the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9zYrr6sfkA6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2156b2bc-64cc-4bd8-90d9-7b8a7b67b30a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:229: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "merged_model = model.merge_and_unload()\n",
        "\n",
        "# this will fail until the following work merged into Huggingface Transformers repo is published to pip:\n",
        "# https://github.com/huggingface/transformers/pull/26037\n",
        "# merged_model.save_pretrained(\n",
        "#     new_model_id,\n",
        "#     push_to_hub=True,\n",
        "#     repo_id=new_model_id,\n",
        "#     private=False,\n",
        "#     use_auth_token=userdata.get('HF_TOKEN'),\n",
        "# )\n",
        "# tokenizer.save_pretrained(\n",
        "#     new_model_id,\n",
        "#     push_to_hub=True,\n",
        "#     repo_id=new_model_id,\n",
        "#     private=False,\n",
        "#     use_auth_token=userdata.get('HF_TOKEN'),\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NySwQs8blN7q"
      },
      "source": [
        "Now generate a response with the fine-tuned model for comparison:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "c1Eo6D2mnOgN"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt, model):\n",
        "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "  model_inputs = encoded_input.to('cuda')\n",
        "\n",
        "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  return decoded_output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "J0wI38Wo9sKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "57f92955-bc36-4783-c3dd-71ceaf78e4ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s><s> [INST] Write a SQL query or use a function to answer the following question. Use the SQL dialect Presto for AWS Athena.\\n\\nWhat is the average age of the dogs who have gone through any treatments? [/INST] ```sql\\nSELECT AVG(age)\\nFROM treatments\\nJOIN dogs ON treatments.dog_id = dogs.id\\n```</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "generate_response(prompt, merged_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtpyNHhsGSWs"
      },
      "source": [
        "**Optional**: merge LoRA into pretrained, unquantized model. Then store on either Google Drive or Huggingface. Won't be necessary once saving and uploading 4bit quantized models is enabled by Huggingface Transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zv39NUIR-HQ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "2ef4f578d63a4b0b8782cd4a9f535747",
            "fb9ab1e399e74939b27fabe159b6a1b2",
            "b867ef0510b54a0c8e2103073512a920",
            "0975a4bc7a2743e7a8051c70f7b31846",
            "262162a8baa8454488f916339ea078ab",
            "42c39d1a610a4e94be5f3eed0725dfc2",
            "fe062ed8025c48c38164c81034fbc6fb",
            "4bb1f943883c408aa9f4ffe37d8906cd",
            "a8e5e952f0c0426d86c7234468910859",
            "bb99994d85b340d8bbea0f84cb51ea01",
            "e73264b4befb4edf95ab4423e750a5c8",
            "13c3f29780ba41cbb3f7f497b4952f8a",
            "41ab6a43fd5941939a2c959cb9bf1cd5",
            "8e92906148db4d448d7c5112b7dd3958",
            "f671f11b26194d47b1ba9ba18ca7d0c2",
            "4b241ed1acf9410db62166631c5601a1",
            "1d18fe4bfd9249c29a250dc59091a96d",
            "f73cd88ac27d4d858ba1145cda318ea2",
            "3e1ea1914c664e0c948f1c06595a5ce4",
            "d84e01a8f2a14518a1b86cd752519226",
            "cf1ddf035d2a4835a81904a70c5c4d28",
            "261d7639991f44a9bbdfbef28aad7761",
            "2d03cfe9650b4d08b2234995a224065f",
            "6606f2d293994f4a9e2fe8381b63d0d8",
            "19ffd17804d647bfb1c0e292fb2264cf",
            "8d8af8a695e94070bf502664c80289ed",
            "4022d257ecc840b8a7afb69d4aeb306d",
            "2f6c3bc2ed5740139a191ee733af34da",
            "583273e7bf3a4990a024e798d47c3a73",
            "5a6f4d2bbfde48d59d449be12f77b586",
            "9216eb14a3ed4aada32327a3b6c5d878",
            "a9e8f828d83e42dbb71f8be530f90056",
            "e7ac850103774185a5629b58b86f9971",
            "c6bb369c5afa49daa408f9ecfffdb4a0",
            "15bd21c93a50479ba748dc5ea382c37f",
            "1affa4a1f6c04e2d925f140ff36ed7db",
            "a0058572a14c468eb65b1b92ea6213c8",
            "a105d03a0e8f42d49148d877df8a0f2d",
            "21f562b2afee4630846166e05f366ec6",
            "b75bd2b58a5d4aa4bf772847c881a71a",
            "1580136cd21444b1a83b9517271bf85e",
            "4763a628201a4388b55e2478b05b08b9",
            "ec388726c99b4694bb031ffc3a0c951f",
            "dabd8681922848c6bde4e8725a301f8c",
            "f7c533aa7e8f4202b9e88ce1b68c5ad3",
            "911b9a0a542146f3a3cdff88be9ab6ca",
            "456b7cfab2cd4bd8b4cacc768daf09e3",
            "521ecda57031431683b05dd4ec1ad5b9",
            "17865eb9b809416187bec7d7755a0cba",
            "a6be1a38d85d4ebbac8b818cb8c0f82a",
            "efa45522a8ae43e591374869006fdd0a",
            "5c9f310eaecc409d8948539aab6bc2e0",
            "1f8aa41233014eb496d5267bbc43f9d5",
            "78ea76317eac4430aaccb059d0d58211",
            "4dc2de5d917642f2b527634e7b4d2c79",
            "c970f0c79b344ead9b60500b73654342",
            "6d5a5a6678d34d38a2839a6ec6d315b8",
            "faa70417d49c4d53aafc132f509237f2",
            "98d0106e8e3a451d965ca6befe638cea",
            "f7dbc15907c74007a77b0557027d8bad",
            "5cdf61dd3e264d17a7423e9e2aa5b0c1",
            "1b17484016434046be6db68fe40dbc03",
            "0b86c8442d3645d095d578a89777c533",
            "cd8a265df04746f88a4314e03119a5c2",
            "f143cfabc21c4c1f9ef827dea04a708a",
            "bd48abe89023498ca752332b18f683d2"
          ]
        },
        "outputId": "46b80e2f-34d0-4121-a394-b85c81f37df7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading base model:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ef4f578d63a4b0b8782cd4a9f535747"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13c3f29780ba41cbb3f7f497b4952f8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading Peft model:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d03cfe9650b4d08b2234995a224065f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/586 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6bb369c5afa49daa408f9ecfffdb4a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7c533aa7e8f4202b9e88ce1b68c5ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Merge and Unload:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c970f0c79b344ead9b60500b73654342"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import os\n",
        "import logging\n",
        "from tqdm.notebook import tqdm  # Use notebook version of tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "huggingface_model_path = new_model_id\n",
        "\n",
        "# Manually set your parameters here\n",
        "base_model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "peft_model_path = f\"cnatale/{modelname}\"\n",
        "# output_dir = f\"/content/drive/MyDrive/{modelname}\"\n",
        "output_dir = f\"/content/{modelname}\"\n",
        "device = \"auto\"  # set to 'auto' or specify device like 'cuda:0'\n",
        "push_to_hub = True  # set to True if you want to push to the Hugging Face Model Hub\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    if device == 'auto':\n",
        "        device_arg = {'device_map': 'auto'}\n",
        "    else:\n",
        "        device_arg = {'device_map': {\"\": device}}\n",
        "\n",
        "    logger.info(f\"Loading base model: {base_model_name_or_path}\")\n",
        "    with tqdm(total=1, desc=\"Loading base model\") as pbar:\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            base_model_name_or_path,\n",
        "            return_dict=True,\n",
        "            torch_dtype=torch.float16,\n",
        "            **device_arg\n",
        "        )\n",
        "        pbar.update(1)\n",
        "\n",
        "    logger.info(f\"Loading Peft: {peft_model_path}\")\n",
        "    with tqdm(total=1, desc=\"Loading Peft model\") as pbar:\n",
        "        model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
        "        pbar.update(1)\n",
        "\n",
        "    logger.info(\"Running merge_and_unload\")\n",
        "    with tqdm(total=1, desc=\"Merge and Unload\") as pbar:\n",
        "        model = model.merge_and_unload()\n",
        "        pbar.update(1)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path)\n",
        "\n",
        "    # Save the data to a Google Drive or local directory\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    model.save_pretrained(f\"{output_dir}\")\n",
        "    tokenizer.save_pretrained(f\"{output_dir}\")\n",
        "    logger.info(f\"Model saved to {output_dir}\")\n",
        "\n",
        "    # Alternatively, push the model directly to Huggingface repo\n",
        "    # model.save_pretrained(\n",
        "    #     new_model_id,\n",
        "    #     push_to_hub=True,\n",
        "    #     repo_id=new_model_id,\n",
        "    #     private=False,\n",
        "    #     use_auth_token=userdata.get('HF_TOKEN'),\n",
        "    # )\n",
        "    # tokenizer.save_pretrained(\n",
        "    #     new_model_id,\n",
        "    #     push_to_hub=True,\n",
        "    #     repo_id=new_model_id,\n",
        "    #     private=False,\n",
        "    #     use_auth_token=userdata.get('HF_TOKEN'),\n",
        "    # )\n",
        "\n",
        "except Exception as e:\n",
        "    logger.exception(\"An error occurred:\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp3eVQCJTD9e"
      },
      "source": [
        "# Quantize the Model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ROy8XJaUTDq8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8f42521-2933-4cb7-a9d9-ad41c64d2716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 15014, done.\u001b[K\n",
            "remote: Counting objects: 100% (1523/1523), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 15014 (delta 1477), reused 1474 (delta 1456), pack-reused 13491\u001b[K\n",
            "Receiving objects: 100% (15014/15014), 17.72 MiB | 16.59 MiB/s, done.\n",
            "Resolving deltas: 100% (10420/10420), done.\n",
            "Already up to date.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi\n",
            "I NVCCFLAGS:  \n",
            "I LDFLAGS:    \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "rm -vrf *.o tests/*.o *.so *.dll benchmark-matmult common/build-info.cpp *.dot *.gcno tests/*.gcno *.gcda tests/*.gcda *.gcov tests/*.gcov lcov-report gcovr-report main quantize quantize-stats perplexity embedding vdot q8dot train-text-from-scratch convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf llama-bench libllava.a llava-cli baby-llama beam-search speculative infill tokenize benchmark-matmult parallel finetune export-lora lookahead lookup tests/test-c.o metal tests/test-llama-grammar tests/test-grammar-parser tests/test-double-float tests/test-grad0 tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-sampling tests/test-tokenizer-0-llama tests/test-tokenizer-0-falcon tests/test-tokenizer-1-llama tests/test-tokenizer-1-bpe tests/test-rope tests/test-backend-ops\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi\n",
            "I NVCCFLAGS: -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 \n",
            "I LDFLAGS:   -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml.c -o ggml.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -c llama.cpp -o llama.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -c common/common.cpp -o common.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -c common/sampling.cpp -o sampling.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -c common/grammar-parser.cpp -o grammar-parser.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -c common/build-info.cpp -o build-info.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -c common/console.cpp -o console.o\n",
            "nvcc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Wno-pedantic -Xcompiler \"-Wno-array-bounds -Wno-format-truncation -Wextra-semi\" -c ggml-cuda.cu -o ggml-cuda.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-alloc.c -o ggml-alloc.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-backend.c -o ggml-backend.o\n",
            "cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion     -c ggml-quants.c -o ggml-quants.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/main/main.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o console.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o main -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "\n",
            "====  Run ./main -h for help.  ====\n",
            "\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/quantize/quantize.cpp build-info.o ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o quantize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/quantize-stats/quantize-stats.cpp build-info.o ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o quantize-stats -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/perplexity/perplexity.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o perplexity -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/embedding/embedding.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o embedding -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi pocs/vdot/vdot.cpp ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o vdot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi pocs/vdot/q8dot.cpp ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o q8dot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -c common/train.cpp -o train.o\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/train-text-from-scratch/train-text-from-scratch.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o train-text-from-scratch -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o convert-llama2c-to-ggml -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/simple/simple.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o simple -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/batched/batched.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o batched -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/batched-bench/batched-bench.cpp build-info.o ggml.o llama.o common.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o batched-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/save-load-state/save-load-state.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o save-load-state -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iexamples/server examples/server/server.cpp examples/llava/clip.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o server -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib   -Wno-cast-qual\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/gguf/gguf.cpp ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o gguf -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/llama-bench/llama-bench.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o llama-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -static -fPIC -c examples/llava/llava.cpp -o libllava.a -Wno-cast-qual\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/llava/llava-cli.cpp examples/llava/clip.cpp examples/llava/llava.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o llava-cli -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib  -Wno-cast-qual\n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/baby-llama/baby-llama.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o baby-llama -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/beam-search/beam-search.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o beam-search -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/speculative/speculative.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o speculative -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/infill/infill.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o console.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o infill -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/tokenize/tokenize.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o tokenize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/benchmark/benchmark-matmult.cpp build-info.o ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o benchmark-matmult -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/parallel/parallel.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o parallel -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/finetune/finetune.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o finetune -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/export-lora/export-lora.cpp ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o export-lora -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/lookahead/lookahead.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o lookahead -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi examples/lookup/lookup.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o -o lookup -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion  -c tests/test-c.c -o tests/test-c.o\n",
            "Collecting numpy~=1.24.4 (from -r llama.cpp/./requirements/requirements-convert.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece~=0.1.98 (from -r llama.cpp/./requirements/requirements-convert.txt (line 2))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.35.2 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.36.2)\n",
            "Collecting gguf>=0.1.0 (from -r llama.cpp/./requirements/requirements-convert.txt (line 4))\n",
            "  Downloading gguf-0.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting protobuf<5.0.0,>=4.21.0 (from -r llama.cpp/./requirements/requirements-convert.txt (line 5))\n",
            "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch~=2.1.1 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.20.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: sentencepiece, protobuf, numpy, gguf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gguf-0.6.0 numpy-1.24.4 protobuf-4.25.1 sentencepiece-0.1.99\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install llama.cpp\n",
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "!cd llama.cpp && git pull && make clean && LLAMA_CUBLAS=1 make\n",
        "!pip install -r llama.cpp/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-_YvnRUETVU9"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = f\"cnatale/{modelname}\"\n",
        "\n",
        "# Download model - skip if possible because this take a long time\n",
        "#!git lfs install\n",
        "#!git clone https://huggingface.co/{MODEL_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG9U-l9RTZep"
      },
      "source": [
        "Next, convert weights to GGUF FP16 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RcVBavBrTf_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52feb41a-f07c-4d84-fc84-2e91710dad85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model file Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/model-00001-of-00003.safetensors\n",
            "Loading model file Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/model-00001-of-00003.safetensors\n",
            "Loading model file Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/model-00002-of-00003.safetensors\n",
            "Loading model file Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/model-00003-of-00003.safetensors\n",
            "params = Params(n_vocab=32000, n_embd=4096, n_layer=32, n_ctx=32768, n_ff=14336, n_head=32, n_head_kv=8, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=10000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=<GGMLFileType.MostlyF16: 1>, path_model=PosixPath('Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL'))\n",
            "Vocab info: <VocabLoader with 32000 base tokens and 0 added tokens>\n",
            "Special vocab info: <SpecialVocab with 58980 merges, special tokens {'bos': 1, 'eos': 2, 'unk': 0}, add special tokens {'bos': True, 'eos': False}>\n",
            "Permuting layer 0\n",
            "Permuting layer 1\n",
            "Permuting layer 2\n",
            "Permuting layer 3\n",
            "Permuting layer 4\n",
            "Permuting layer 5\n",
            "Permuting layer 6\n",
            "Permuting layer 7\n",
            "Permuting layer 8\n",
            "Permuting layer 9\n",
            "Permuting layer 10\n",
            "Permuting layer 11\n",
            "Permuting layer 12\n",
            "Permuting layer 13\n",
            "Permuting layer 14\n",
            "Permuting layer 15\n",
            "Permuting layer 16\n",
            "Permuting layer 17\n",
            "Permuting layer 18\n",
            "Permuting layer 19\n",
            "Permuting layer 20\n",
            "Permuting layer 21\n",
            "Permuting layer 22\n",
            "Permuting layer 23\n",
            "Permuting layer 24\n",
            "Permuting layer 25\n",
            "Permuting layer 26\n",
            "Permuting layer 27\n",
            "Permuting layer 28\n",
            "Permuting layer 29\n",
            "Permuting layer 30\n",
            "Permuting layer 31\n",
            "model.embed_tokens.weight                        -> token_embd.weight                        | F16    | [32000, 4096]\n",
            "model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.1.mlp.down_proj.weight              -> blk.1.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.1.mlp.gate_proj.weight              -> blk.1.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.1.mlp.up_proj.weight                -> blk.1.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.1.post_attention_layernorm.weight   -> blk.1.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.1.self_attn.k_proj.weight           -> blk.1.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.self_attn.o_proj.weight           -> blk.1.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.1.self_attn.q_proj.weight           -> blk.1.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.1.self_attn.v_proj.weight           -> blk.1.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.10.mlp.gate_proj.weight             -> blk.10.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.10.mlp.up_proj.weight               -> blk.10.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.10.self_attn.k_proj.weight          -> blk.10.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.10.self_attn.o_proj.weight          -> blk.10.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.10.self_attn.q_proj.weight          -> blk.10.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.10.self_attn.v_proj.weight          -> blk.10.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.2.input_layernorm.weight            -> blk.2.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.2.mlp.down_proj.weight              -> blk.2.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.2.mlp.gate_proj.weight              -> blk.2.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.2.mlp.up_proj.weight                -> blk.2.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.2.post_attention_layernorm.weight   -> blk.2.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.2.self_attn.k_proj.weight           -> blk.2.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.2.self_attn.o_proj.weight           -> blk.2.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.2.self_attn.q_proj.weight           -> blk.2.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.2.self_attn.v_proj.weight           -> blk.2.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.input_layernorm.weight            -> blk.3.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.3.mlp.down_proj.weight              -> blk.3.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.3.mlp.gate_proj.weight              -> blk.3.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.3.mlp.up_proj.weight                -> blk.3.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.3.post_attention_layernorm.weight   -> blk.3.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.3.self_attn.k_proj.weight           -> blk.3.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.self_attn.o_proj.weight           -> blk.3.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.3.self_attn.q_proj.weight           -> blk.3.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.3.self_attn.v_proj.weight           -> blk.3.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.input_layernorm.weight            -> blk.4.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.4.mlp.down_proj.weight              -> blk.4.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.4.mlp.gate_proj.weight              -> blk.4.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.4.mlp.up_proj.weight                -> blk.4.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.4.post_attention_layernorm.weight   -> blk.4.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.4.self_attn.k_proj.weight           -> blk.4.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.self_attn.o_proj.weight           -> blk.4.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.4.self_attn.q_proj.weight           -> blk.4.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.4.self_attn.v_proj.weight           -> blk.4.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.input_layernorm.weight            -> blk.5.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.5.mlp.down_proj.weight              -> blk.5.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.5.mlp.gate_proj.weight              -> blk.5.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.5.mlp.up_proj.weight                -> blk.5.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.5.post_attention_layernorm.weight   -> blk.5.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.5.self_attn.k_proj.weight           -> blk.5.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.self_attn.o_proj.weight           -> blk.5.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.5.self_attn.q_proj.weight           -> blk.5.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.5.self_attn.v_proj.weight           -> blk.5.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.input_layernorm.weight            -> blk.6.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.6.mlp.down_proj.weight              -> blk.6.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.6.mlp.gate_proj.weight              -> blk.6.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.6.mlp.up_proj.weight                -> blk.6.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.6.post_attention_layernorm.weight   -> blk.6.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.6.self_attn.k_proj.weight           -> blk.6.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.self_attn.o_proj.weight           -> blk.6.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.6.self_attn.q_proj.weight           -> blk.6.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.6.self_attn.v_proj.weight           -> blk.6.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.input_layernorm.weight            -> blk.7.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.7.mlp.down_proj.weight              -> blk.7.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.7.mlp.gate_proj.weight              -> blk.7.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.7.mlp.up_proj.weight                -> blk.7.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.7.post_attention_layernorm.weight   -> blk.7.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.7.self_attn.k_proj.weight           -> blk.7.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.self_attn.o_proj.weight           -> blk.7.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.7.self_attn.q_proj.weight           -> blk.7.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.7.self_attn.v_proj.weight           -> blk.7.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.input_layernorm.weight            -> blk.8.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.8.mlp.down_proj.weight              -> blk.8.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.8.mlp.gate_proj.weight              -> blk.8.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.8.mlp.up_proj.weight                -> blk.8.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.8.post_attention_layernorm.weight   -> blk.8.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.8.self_attn.k_proj.weight           -> blk.8.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.self_attn.o_proj.weight           -> blk.8.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.8.self_attn.q_proj.weight           -> blk.8.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.8.self_attn.v_proj.weight           -> blk.8.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.input_layernorm.weight            -> blk.9.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.9.mlp.down_proj.weight              -> blk.9.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.9.mlp.gate_proj.weight              -> blk.9.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.9.mlp.up_proj.weight                -> blk.9.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.9.post_attention_layernorm.weight   -> blk.9.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.9.self_attn.k_proj.weight           -> blk.9.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.self_attn.o_proj.weight           -> blk.9.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.9.self_attn.q_proj.weight           -> blk.9.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.9.self_attn.v_proj.weight           -> blk.9.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.10.input_layernorm.weight           -> blk.10.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.10.mlp.down_proj.weight             -> blk.10.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.10.post_attention_layernorm.weight  -> blk.10.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.11.input_layernorm.weight           -> blk.11.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.11.mlp.down_proj.weight             -> blk.11.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.11.mlp.gate_proj.weight             -> blk.11.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.11.mlp.up_proj.weight               -> blk.11.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.11.post_attention_layernorm.weight  -> blk.11.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.11.self_attn.k_proj.weight          -> blk.11.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.11.self_attn.o_proj.weight          -> blk.11.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.11.self_attn.q_proj.weight          -> blk.11.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.11.self_attn.v_proj.weight          -> blk.11.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.input_layernorm.weight           -> blk.12.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.12.mlp.down_proj.weight             -> blk.12.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.12.mlp.gate_proj.weight             -> blk.12.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.12.mlp.up_proj.weight               -> blk.12.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.12.post_attention_layernorm.weight  -> blk.12.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.12.self_attn.k_proj.weight          -> blk.12.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.self_attn.o_proj.weight          -> blk.12.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.12.self_attn.q_proj.weight          -> blk.12.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.12.self_attn.v_proj.weight          -> blk.12.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.input_layernorm.weight           -> blk.13.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.13.mlp.down_proj.weight             -> blk.13.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.13.mlp.gate_proj.weight             -> blk.13.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.13.mlp.up_proj.weight               -> blk.13.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.13.post_attention_layernorm.weight  -> blk.13.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.13.self_attn.k_proj.weight          -> blk.13.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.self_attn.o_proj.weight          -> blk.13.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.13.self_attn.q_proj.weight          -> blk.13.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.13.self_attn.v_proj.weight          -> blk.13.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.input_layernorm.weight           -> blk.14.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.14.mlp.down_proj.weight             -> blk.14.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.14.mlp.gate_proj.weight             -> blk.14.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.14.mlp.up_proj.weight               -> blk.14.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.14.post_attention_layernorm.weight  -> blk.14.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.14.self_attn.k_proj.weight          -> blk.14.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.self_attn.o_proj.weight          -> blk.14.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.14.self_attn.q_proj.weight          -> blk.14.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.14.self_attn.v_proj.weight          -> blk.14.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.input_layernorm.weight           -> blk.15.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.15.mlp.down_proj.weight             -> blk.15.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.15.mlp.gate_proj.weight             -> blk.15.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.15.mlp.up_proj.weight               -> blk.15.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.15.post_attention_layernorm.weight  -> blk.15.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.15.self_attn.k_proj.weight          -> blk.15.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.self_attn.o_proj.weight          -> blk.15.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.15.self_attn.q_proj.weight          -> blk.15.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.15.self_attn.v_proj.weight          -> blk.15.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.input_layernorm.weight           -> blk.16.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.16.mlp.down_proj.weight             -> blk.16.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.16.mlp.gate_proj.weight             -> blk.16.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.16.mlp.up_proj.weight               -> blk.16.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.16.post_attention_layernorm.weight  -> blk.16.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.16.self_attn.k_proj.weight          -> blk.16.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.self_attn.o_proj.weight          -> blk.16.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.16.self_attn.q_proj.weight          -> blk.16.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.16.self_attn.v_proj.weight          -> blk.16.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.input_layernorm.weight           -> blk.17.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.17.mlp.down_proj.weight             -> blk.17.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.17.mlp.gate_proj.weight             -> blk.17.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.17.mlp.up_proj.weight               -> blk.17.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.17.post_attention_layernorm.weight  -> blk.17.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.17.self_attn.k_proj.weight          -> blk.17.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.self_attn.o_proj.weight          -> blk.17.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.17.self_attn.q_proj.weight          -> blk.17.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.17.self_attn.v_proj.weight          -> blk.17.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.input_layernorm.weight           -> blk.18.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.18.mlp.down_proj.weight             -> blk.18.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.18.mlp.gate_proj.weight             -> blk.18.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.18.mlp.up_proj.weight               -> blk.18.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.18.post_attention_layernorm.weight  -> blk.18.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.18.self_attn.k_proj.weight          -> blk.18.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.self_attn.o_proj.weight          -> blk.18.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.18.self_attn.q_proj.weight          -> blk.18.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.18.self_attn.v_proj.weight          -> blk.18.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.input_layernorm.weight           -> blk.19.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.19.mlp.down_proj.weight             -> blk.19.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.19.mlp.gate_proj.weight             -> blk.19.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.19.mlp.up_proj.weight               -> blk.19.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.19.post_attention_layernorm.weight  -> blk.19.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.19.self_attn.k_proj.weight          -> blk.19.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.self_attn.o_proj.weight          -> blk.19.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.19.self_attn.q_proj.weight          -> blk.19.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.19.self_attn.v_proj.weight          -> blk.19.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.input_layernorm.weight           -> blk.20.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.20.mlp.down_proj.weight             -> blk.20.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.20.mlp.gate_proj.weight             -> blk.20.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.20.mlp.up_proj.weight               -> blk.20.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.20.post_attention_layernorm.weight  -> blk.20.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.20.self_attn.k_proj.weight          -> blk.20.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.self_attn.o_proj.weight          -> blk.20.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.20.self_attn.q_proj.weight          -> blk.20.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.20.self_attn.v_proj.weight          -> blk.20.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.input_layernorm.weight           -> blk.21.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.21.mlp.down_proj.weight             -> blk.21.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.21.mlp.gate_proj.weight             -> blk.21.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.21.mlp.up_proj.weight               -> blk.21.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.21.post_attention_layernorm.weight  -> blk.21.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.21.self_attn.k_proj.weight          -> blk.21.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.self_attn.o_proj.weight          -> blk.21.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.21.self_attn.q_proj.weight          -> blk.21.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.21.self_attn.v_proj.weight          -> blk.21.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.k_proj.weight          -> blk.22.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.o_proj.weight          -> blk.22.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.22.self_attn.q_proj.weight          -> blk.22.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.22.self_attn.v_proj.weight          -> blk.22.attn_v.weight                     | F16    | [1024, 4096]\n",
            "lm_head.weight                                   -> output.weight                            | F16    | [32000, 4096]\n",
            "model.layers.22.input_layernorm.weight           -> blk.22.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.22.mlp.down_proj.weight             -> blk.22.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.22.mlp.gate_proj.weight             -> blk.22.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.22.mlp.up_proj.weight               -> blk.22.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.22.post_attention_layernorm.weight  -> blk.22.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.23.input_layernorm.weight           -> blk.23.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.23.mlp.down_proj.weight             -> blk.23.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.23.mlp.gate_proj.weight             -> blk.23.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.23.mlp.up_proj.weight               -> blk.23.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.23.post_attention_layernorm.weight  -> blk.23.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.23.self_attn.k_proj.weight          -> blk.23.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.23.self_attn.o_proj.weight          -> blk.23.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.23.self_attn.q_proj.weight          -> blk.23.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.23.self_attn.v_proj.weight          -> blk.23.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.input_layernorm.weight           -> blk.24.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.24.mlp.down_proj.weight             -> blk.24.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.24.mlp.gate_proj.weight             -> blk.24.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.24.mlp.up_proj.weight               -> blk.24.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.24.post_attention_layernorm.weight  -> blk.24.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.24.self_attn.k_proj.weight          -> blk.24.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.self_attn.o_proj.weight          -> blk.24.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.24.self_attn.q_proj.weight          -> blk.24.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.24.self_attn.v_proj.weight          -> blk.24.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.input_layernorm.weight           -> blk.25.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.25.mlp.down_proj.weight             -> blk.25.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.25.mlp.gate_proj.weight             -> blk.25.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.25.mlp.up_proj.weight               -> blk.25.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.25.post_attention_layernorm.weight  -> blk.25.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.25.self_attn.k_proj.weight          -> blk.25.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.self_attn.o_proj.weight          -> blk.25.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.25.self_attn.q_proj.weight          -> blk.25.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.25.self_attn.v_proj.weight          -> blk.25.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.input_layernorm.weight           -> blk.26.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.26.mlp.down_proj.weight             -> blk.26.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.26.mlp.gate_proj.weight             -> blk.26.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.26.mlp.up_proj.weight               -> blk.26.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.26.post_attention_layernorm.weight  -> blk.26.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.26.self_attn.k_proj.weight          -> blk.26.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.self_attn.o_proj.weight          -> blk.26.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.26.self_attn.q_proj.weight          -> blk.26.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.26.self_attn.v_proj.weight          -> blk.26.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.input_layernorm.weight           -> blk.27.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.27.mlp.down_proj.weight             -> blk.27.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.27.mlp.gate_proj.weight             -> blk.27.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.27.mlp.up_proj.weight               -> blk.27.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.27.post_attention_layernorm.weight  -> blk.27.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.27.self_attn.k_proj.weight          -> blk.27.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.self_attn.o_proj.weight          -> blk.27.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.27.self_attn.q_proj.weight          -> blk.27.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.27.self_attn.v_proj.weight          -> blk.27.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.input_layernorm.weight           -> blk.28.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.28.mlp.down_proj.weight             -> blk.28.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.28.mlp.gate_proj.weight             -> blk.28.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.28.mlp.up_proj.weight               -> blk.28.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.28.post_attention_layernorm.weight  -> blk.28.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.28.self_attn.k_proj.weight          -> blk.28.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.self_attn.o_proj.weight          -> blk.28.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.28.self_attn.q_proj.weight          -> blk.28.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.28.self_attn.v_proj.weight          -> blk.28.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.input_layernorm.weight           -> blk.29.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.29.mlp.down_proj.weight             -> blk.29.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.29.mlp.gate_proj.weight             -> blk.29.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.29.mlp.up_proj.weight               -> blk.29.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.29.post_attention_layernorm.weight  -> blk.29.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.29.self_attn.k_proj.weight          -> blk.29.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.self_attn.o_proj.weight          -> blk.29.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.29.self_attn.q_proj.weight          -> blk.29.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.29.self_attn.v_proj.weight          -> blk.29.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.input_layernorm.weight           -> blk.30.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.30.mlp.down_proj.weight             -> blk.30.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.30.mlp.gate_proj.weight             -> blk.30.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.30.mlp.up_proj.weight               -> blk.30.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.30.post_attention_layernorm.weight  -> blk.30.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.30.self_attn.k_proj.weight          -> blk.30.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.self_attn.o_proj.weight          -> blk.30.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.30.self_attn.q_proj.weight          -> blk.30.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.30.self_attn.v_proj.weight          -> blk.30.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.input_layernorm.weight           -> blk.31.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.31.mlp.down_proj.weight             -> blk.31.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.31.mlp.gate_proj.weight             -> blk.31.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.31.mlp.up_proj.weight               -> blk.31.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.31.post_attention_layernorm.weight  -> blk.31.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.31.self_attn.k_proj.weight          -> blk.31.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.self_attn.o_proj.weight          -> blk.31.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.31.self_attn.q_proj.weight          -> blk.31.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.31.self_attn.v_proj.weight          -> blk.31.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.norm.weight                                -> output_norm.weight                       | F16    | [4096]\n",
            "Writing Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/mistral-7b-instruct-v0.1-txt-2-presto-sql.fp16.bin, format 1\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "gguf: Adding 58980 merge(s).\n",
            "gguf: Setting special token type bos to 1\n",
            "gguf: Setting special token type eos to 2\n",
            "gguf: Setting special token type unk to 0\n",
            "gguf: Setting add_bos_token to True\n",
            "gguf: Setting add_eos_token to False\n",
            "gguf: Setting chat_template to {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token + ' ' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\n",
            "[  1/291] Writing tensor token_embd.weight                      | size  32000 x   4096  | type F16  | T+   0\n",
            "[  2/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+   0\n",
            "[  3/291] Writing tensor blk.0.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   0\n",
            "[  4/291] Writing tensor blk.0.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   0\n",
            "[  5/291] Writing tensor blk.0.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   0\n",
            "[  6/291] Writing tensor blk.0.ffn_norm.weight                  | size   4096           | type F32  | T+   0\n",
            "[  7/291] Writing tensor blk.0.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   0\n",
            "[  8/291] Writing tensor blk.0.attn_output.weight               | size   4096 x   4096  | type F16  | T+   0\n",
            "[  9/291] Writing tensor blk.0.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   0\n",
            "[ 10/291] Writing tensor blk.0.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   0\n",
            "[ 11/291] Writing tensor blk.1.attn_norm.weight                 | size   4096           | type F32  | T+   0\n",
            "[ 12/291] Writing tensor blk.1.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   0\n",
            "[ 13/291] Writing tensor blk.1.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   0\n",
            "[ 14/291] Writing tensor blk.1.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   0\n",
            "[ 15/291] Writing tensor blk.1.ffn_norm.weight                  | size   4096           | type F32  | T+   0\n",
            "[ 16/291] Writing tensor blk.1.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   0\n",
            "[ 17/291] Writing tensor blk.1.attn_output.weight               | size   4096 x   4096  | type F16  | T+   0\n",
            "[ 18/291] Writing tensor blk.1.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   0\n",
            "[ 19/291] Writing tensor blk.1.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   0\n",
            "[ 20/291] Writing tensor blk.10.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+   0\n",
            "[ 21/291] Writing tensor blk.10.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+   1\n",
            "[ 22/291] Writing tensor blk.10.attn_k.weight                   | size   1024 x   4096  | type F16  | T+   1\n",
            "[ 23/291] Writing tensor blk.10.attn_output.weight              | size   4096 x   4096  | type F16  | T+   1\n",
            "[ 24/291] Writing tensor blk.10.attn_q.weight                   | size   4096 x   4096  | type F16  | T+   1\n",
            "[ 25/291] Writing tensor blk.10.attn_v.weight                   | size   1024 x   4096  | type F16  | T+   1\n",
            "[ 26/291] Writing tensor blk.2.attn_norm.weight                 | size   4096           | type F32  | T+   1\n",
            "[ 27/291] Writing tensor blk.2.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   1\n",
            "[ 28/291] Writing tensor blk.2.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   1\n",
            "[ 29/291] Writing tensor blk.2.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   1\n",
            "[ 30/291] Writing tensor blk.2.ffn_norm.weight                  | size   4096           | type F32  | T+   1\n",
            "[ 31/291] Writing tensor blk.2.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   1\n",
            "[ 32/291] Writing tensor blk.2.attn_output.weight               | size   4096 x   4096  | type F16  | T+   1\n",
            "[ 33/291] Writing tensor blk.2.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   2\n",
            "[ 34/291] Writing tensor blk.2.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   2\n",
            "[ 35/291] Writing tensor blk.3.attn_norm.weight                 | size   4096           | type F32  | T+   2\n",
            "[ 36/291] Writing tensor blk.3.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   2\n",
            "[ 37/291] Writing tensor blk.3.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   2\n",
            "[ 38/291] Writing tensor blk.3.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   2\n",
            "[ 39/291] Writing tensor blk.3.ffn_norm.weight                  | size   4096           | type F32  | T+   2\n",
            "[ 40/291] Writing tensor blk.3.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   2\n",
            "[ 41/291] Writing tensor blk.3.attn_output.weight               | size   4096 x   4096  | type F16  | T+   2\n",
            "[ 42/291] Writing tensor blk.3.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   2\n",
            "[ 43/291] Writing tensor blk.3.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   2\n",
            "[ 44/291] Writing tensor blk.4.attn_norm.weight                 | size   4096           | type F32  | T+   3\n",
            "[ 45/291] Writing tensor blk.4.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   3\n",
            "[ 46/291] Writing tensor blk.4.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   3\n",
            "[ 47/291] Writing tensor blk.4.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   3\n",
            "[ 48/291] Writing tensor blk.4.ffn_norm.weight                  | size   4096           | type F32  | T+   4\n",
            "[ 49/291] Writing tensor blk.4.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   4\n",
            "[ 50/291] Writing tensor blk.4.attn_output.weight               | size   4096 x   4096  | type F16  | T+   4\n",
            "[ 51/291] Writing tensor blk.4.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   4\n",
            "[ 52/291] Writing tensor blk.4.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   4\n",
            "[ 53/291] Writing tensor blk.5.attn_norm.weight                 | size   4096           | type F32  | T+   4\n",
            "[ 54/291] Writing tensor blk.5.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   4\n",
            "[ 55/291] Writing tensor blk.5.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   4\n",
            "[ 56/291] Writing tensor blk.5.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   4\n",
            "[ 57/291] Writing tensor blk.5.ffn_norm.weight                  | size   4096           | type F32  | T+   5\n",
            "[ 58/291] Writing tensor blk.5.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   5\n",
            "[ 59/291] Writing tensor blk.5.attn_output.weight               | size   4096 x   4096  | type F16  | T+   5\n",
            "[ 60/291] Writing tensor blk.5.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   5\n",
            "[ 61/291] Writing tensor blk.5.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   5\n",
            "[ 62/291] Writing tensor blk.6.attn_norm.weight                 | size   4096           | type F32  | T+   5\n",
            "[ 63/291] Writing tensor blk.6.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   5\n",
            "[ 64/291] Writing tensor blk.6.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   5\n",
            "[ 65/291] Writing tensor blk.6.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   6\n",
            "[ 66/291] Writing tensor blk.6.ffn_norm.weight                  | size   4096           | type F32  | T+   6\n",
            "[ 67/291] Writing tensor blk.6.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   6\n",
            "[ 68/291] Writing tensor blk.6.attn_output.weight               | size   4096 x   4096  | type F16  | T+   6\n",
            "[ 69/291] Writing tensor blk.6.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   6\n",
            "[ 70/291] Writing tensor blk.6.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   7\n",
            "[ 71/291] Writing tensor blk.7.attn_norm.weight                 | size   4096           | type F32  | T+   7\n",
            "[ 72/291] Writing tensor blk.7.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   7\n",
            "[ 73/291] Writing tensor blk.7.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   7\n",
            "[ 74/291] Writing tensor blk.7.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   7\n",
            "[ 75/291] Writing tensor blk.7.ffn_norm.weight                  | size   4096           | type F32  | T+   8\n",
            "[ 76/291] Writing tensor blk.7.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   8\n",
            "[ 77/291] Writing tensor blk.7.attn_output.weight               | size   4096 x   4096  | type F16  | T+   8\n",
            "[ 78/291] Writing tensor blk.7.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   8\n",
            "[ 79/291] Writing tensor blk.7.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   8\n",
            "[ 80/291] Writing tensor blk.8.attn_norm.weight                 | size   4096           | type F32  | T+   8\n",
            "[ 81/291] Writing tensor blk.8.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   8\n",
            "[ 82/291] Writing tensor blk.8.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   9\n",
            "[ 83/291] Writing tensor blk.8.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   9\n",
            "[ 84/291] Writing tensor blk.8.ffn_norm.weight                  | size   4096           | type F32  | T+  10\n",
            "[ 85/291] Writing tensor blk.8.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  10\n",
            "[ 86/291] Writing tensor blk.8.attn_output.weight               | size   4096 x   4096  | type F16  | T+  10\n",
            "[ 87/291] Writing tensor blk.8.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  10\n",
            "[ 88/291] Writing tensor blk.8.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  10\n",
            "[ 89/291] Writing tensor blk.9.attn_norm.weight                 | size   4096           | type F32  | T+  10\n",
            "[ 90/291] Writing tensor blk.9.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  10\n",
            "[ 91/291] Writing tensor blk.9.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  11\n",
            "[ 92/291] Writing tensor blk.9.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  11\n",
            "[ 93/291] Writing tensor blk.9.ffn_norm.weight                  | size   4096           | type F32  | T+  11\n",
            "[ 94/291] Writing tensor blk.9.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  11\n",
            "[ 95/291] Writing tensor blk.9.attn_output.weight               | size   4096 x   4096  | type F16  | T+  11\n",
            "[ 96/291] Writing tensor blk.9.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  12\n",
            "[ 97/291] Writing tensor blk.9.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  12\n",
            "[ 98/291] Writing tensor blk.10.attn_norm.weight                | size   4096           | type F32  | T+  12\n",
            "[ 99/291] Writing tensor blk.10.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  12\n",
            "[100/291] Writing tensor blk.10.ffn_norm.weight                 | size   4096           | type F32  | T+  12\n",
            "[101/291] Writing tensor blk.11.attn_norm.weight                | size   4096           | type F32  | T+  12\n",
            "[102/291] Writing tensor blk.11.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  12\n",
            "[103/291] Writing tensor blk.11.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  12\n",
            "[104/291] Writing tensor blk.11.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  15\n",
            "[105/291] Writing tensor blk.11.ffn_norm.weight                 | size   4096           | type F32  | T+  15\n",
            "[106/291] Writing tensor blk.11.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  15\n",
            "[107/291] Writing tensor blk.11.attn_output.weight              | size   4096 x   4096  | type F16  | T+  15\n",
            "[108/291] Writing tensor blk.11.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  15\n",
            "[109/291] Writing tensor blk.11.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  16\n",
            "[110/291] Writing tensor blk.12.attn_norm.weight                | size   4096           | type F32  | T+  16\n",
            "[111/291] Writing tensor blk.12.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  16\n",
            "[112/291] Writing tensor blk.12.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  16\n",
            "[113/291] Writing tensor blk.12.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  16\n",
            "[114/291] Writing tensor blk.12.ffn_norm.weight                 | size   4096           | type F32  | T+  17\n",
            "[115/291] Writing tensor blk.12.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  17\n",
            "[116/291] Writing tensor blk.12.attn_output.weight              | size   4096 x   4096  | type F16  | T+  17\n",
            "[117/291] Writing tensor blk.12.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  17\n",
            "[118/291] Writing tensor blk.12.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  17\n",
            "[119/291] Writing tensor blk.13.attn_norm.weight                | size   4096           | type F32  | T+  17\n",
            "[120/291] Writing tensor blk.13.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  17\n",
            "[121/291] Writing tensor blk.13.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  18\n",
            "[122/291] Writing tensor blk.13.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  18\n",
            "[123/291] Writing tensor blk.13.ffn_norm.weight                 | size   4096           | type F32  | T+  19\n",
            "[124/291] Writing tensor blk.13.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  19\n",
            "[125/291] Writing tensor blk.13.attn_output.weight              | size   4096 x   4096  | type F16  | T+  19\n",
            "[126/291] Writing tensor blk.13.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  19\n",
            "[127/291] Writing tensor blk.13.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  19\n",
            "[128/291] Writing tensor blk.14.attn_norm.weight                | size   4096           | type F32  | T+  19\n",
            "[129/291] Writing tensor blk.14.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  19\n",
            "[130/291] Writing tensor blk.14.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  20\n",
            "[131/291] Writing tensor blk.14.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  20\n",
            "[132/291] Writing tensor blk.14.ffn_norm.weight                 | size   4096           | type F32  | T+  20\n",
            "[133/291] Writing tensor blk.14.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  20\n",
            "[134/291] Writing tensor blk.14.attn_output.weight              | size   4096 x   4096  | type F16  | T+  20\n",
            "[135/291] Writing tensor blk.14.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  20\n",
            "[136/291] Writing tensor blk.14.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  21\n",
            "[137/291] Writing tensor blk.15.attn_norm.weight                | size   4096           | type F32  | T+  21\n",
            "[138/291] Writing tensor blk.15.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  21\n",
            "[139/291] Writing tensor blk.15.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  21\n",
            "[140/291] Writing tensor blk.15.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  21\n",
            "[141/291] Writing tensor blk.15.ffn_norm.weight                 | size   4096           | type F32  | T+  22\n",
            "[142/291] Writing tensor blk.15.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  22\n",
            "[143/291] Writing tensor blk.15.attn_output.weight              | size   4096 x   4096  | type F16  | T+  22\n",
            "[144/291] Writing tensor blk.15.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  22\n",
            "[145/291] Writing tensor blk.15.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  22\n",
            "[146/291] Writing tensor blk.16.attn_norm.weight                | size   4096           | type F32  | T+  22\n",
            "[147/291] Writing tensor blk.16.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  22\n",
            "[148/291] Writing tensor blk.16.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  22\n",
            "[149/291] Writing tensor blk.16.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  23\n",
            "[150/291] Writing tensor blk.16.ffn_norm.weight                 | size   4096           | type F32  | T+  23\n",
            "[151/291] Writing tensor blk.16.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  23\n",
            "[152/291] Writing tensor blk.16.attn_output.weight              | size   4096 x   4096  | type F16  | T+  23\n",
            "[153/291] Writing tensor blk.16.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  23\n",
            "[154/291] Writing tensor blk.16.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  23\n",
            "[155/291] Writing tensor blk.17.attn_norm.weight                | size   4096           | type F32  | T+  23\n",
            "[156/291] Writing tensor blk.17.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  23\n",
            "[157/291] Writing tensor blk.17.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  23\n",
            "[158/291] Writing tensor blk.17.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  24\n",
            "[159/291] Writing tensor blk.17.ffn_norm.weight                 | size   4096           | type F32  | T+  24\n",
            "[160/291] Writing tensor blk.17.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  24\n",
            "[161/291] Writing tensor blk.17.attn_output.weight              | size   4096 x   4096  | type F16  | T+  24\n",
            "[162/291] Writing tensor blk.17.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  24\n",
            "[163/291] Writing tensor blk.17.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  24\n",
            "[164/291] Writing tensor blk.18.attn_norm.weight                | size   4096           | type F32  | T+  24\n",
            "[165/291] Writing tensor blk.18.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  24\n",
            "[166/291] Writing tensor blk.18.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  25\n",
            "[167/291] Writing tensor blk.18.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  25\n",
            "[168/291] Writing tensor blk.18.ffn_norm.weight                 | size   4096           | type F32  | T+  26\n",
            "[169/291] Writing tensor blk.18.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  26\n",
            "[170/291] Writing tensor blk.18.attn_output.weight              | size   4096 x   4096  | type F16  | T+  26\n",
            "[171/291] Writing tensor blk.18.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  27\n",
            "[172/291] Writing tensor blk.18.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  27\n",
            "[173/291] Writing tensor blk.19.attn_norm.weight                | size   4096           | type F32  | T+  27\n",
            "[174/291] Writing tensor blk.19.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  27\n",
            "[175/291] Writing tensor blk.19.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  27\n",
            "[176/291] Writing tensor blk.19.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  27\n",
            "[177/291] Writing tensor blk.19.ffn_norm.weight                 | size   4096           | type F32  | T+  27\n",
            "[178/291] Writing tensor blk.19.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  27\n",
            "[179/291] Writing tensor blk.19.attn_output.weight              | size   4096 x   4096  | type F16  | T+  27\n",
            "[180/291] Writing tensor blk.19.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  27\n",
            "[181/291] Writing tensor blk.19.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  28\n",
            "[182/291] Writing tensor blk.20.attn_norm.weight                | size   4096           | type F32  | T+  28\n",
            "[183/291] Writing tensor blk.20.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  28\n",
            "[184/291] Writing tensor blk.20.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  28\n",
            "[185/291] Writing tensor blk.20.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  28\n",
            "[186/291] Writing tensor blk.20.ffn_norm.weight                 | size   4096           | type F32  | T+  29\n",
            "[187/291] Writing tensor blk.20.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  29\n",
            "[188/291] Writing tensor blk.20.attn_output.weight              | size   4096 x   4096  | type F16  | T+  29\n",
            "[189/291] Writing tensor blk.20.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  29\n",
            "[190/291] Writing tensor blk.20.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  29\n",
            "[191/291] Writing tensor blk.21.attn_norm.weight                | size   4096           | type F32  | T+  29\n",
            "[192/291] Writing tensor blk.21.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  29\n",
            "[193/291] Writing tensor blk.21.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  29\n",
            "[194/291] Writing tensor blk.21.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  29\n",
            "[195/291] Writing tensor blk.21.ffn_norm.weight                 | size   4096           | type F32  | T+  29\n",
            "[196/291] Writing tensor blk.21.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  29\n",
            "[197/291] Writing tensor blk.21.attn_output.weight              | size   4096 x   4096  | type F16  | T+  29\n",
            "[198/291] Writing tensor blk.21.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  29\n",
            "[199/291] Writing tensor blk.21.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  29\n",
            "[200/291] Writing tensor blk.22.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  29\n",
            "[201/291] Writing tensor blk.22.attn_output.weight              | size   4096 x   4096  | type F16  | T+  30\n",
            "[202/291] Writing tensor blk.22.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  30\n",
            "[203/291] Writing tensor blk.22.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  30\n",
            "[204/291] Writing tensor output.weight                          | size  32000 x   4096  | type F16  | T+  30\n",
            "[205/291] Writing tensor blk.22.attn_norm.weight                | size   4096           | type F32  | T+  31\n",
            "[206/291] Writing tensor blk.22.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  31\n",
            "[207/291] Writing tensor blk.22.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  31\n",
            "[208/291] Writing tensor blk.22.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  31\n",
            "[209/291] Writing tensor blk.22.ffn_norm.weight                 | size   4096           | type F32  | T+  32\n",
            "[210/291] Writing tensor blk.23.attn_norm.weight                | size   4096           | type F32  | T+  32\n",
            "[211/291] Writing tensor blk.23.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  32\n",
            "[212/291] Writing tensor blk.23.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  32\n",
            "[213/291] Writing tensor blk.23.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  33\n",
            "[214/291] Writing tensor blk.23.ffn_norm.weight                 | size   4096           | type F32  | T+  33\n",
            "[215/291] Writing tensor blk.23.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  33\n",
            "[216/291] Writing tensor blk.23.attn_output.weight              | size   4096 x   4096  | type F16  | T+  33\n",
            "[217/291] Writing tensor blk.23.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  34\n",
            "[218/291] Writing tensor blk.23.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  34\n",
            "[219/291] Writing tensor blk.24.attn_norm.weight                | size   4096           | type F32  | T+  34\n",
            "[220/291] Writing tensor blk.24.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  34\n",
            "[221/291] Writing tensor blk.24.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  34\n",
            "[222/291] Writing tensor blk.24.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  35\n",
            "[223/291] Writing tensor blk.24.ffn_norm.weight                 | size   4096           | type F32  | T+  35\n",
            "[224/291] Writing tensor blk.24.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  35\n",
            "[225/291] Writing tensor blk.24.attn_output.weight              | size   4096 x   4096  | type F16  | T+  35\n",
            "[226/291] Writing tensor blk.24.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  35\n",
            "[227/291] Writing tensor blk.24.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  35\n",
            "[228/291] Writing tensor blk.25.attn_norm.weight                | size   4096           | type F32  | T+  35\n",
            "[229/291] Writing tensor blk.25.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  35\n",
            "[230/291] Writing tensor blk.25.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  36\n",
            "[231/291] Writing tensor blk.25.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  36\n",
            "[232/291] Writing tensor blk.25.ffn_norm.weight                 | size   4096           | type F32  | T+  37\n",
            "[233/291] Writing tensor blk.25.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  37\n",
            "[234/291] Writing tensor blk.25.attn_output.weight              | size   4096 x   4096  | type F16  | T+  37\n",
            "[235/291] Writing tensor blk.25.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  37\n",
            "[236/291] Writing tensor blk.25.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  37\n",
            "[237/291] Writing tensor blk.26.attn_norm.weight                | size   4096           | type F32  | T+  37\n",
            "[238/291] Writing tensor blk.26.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  37\n",
            "[239/291] Writing tensor blk.26.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  37\n",
            "[240/291] Writing tensor blk.26.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  38\n",
            "[241/291] Writing tensor blk.26.ffn_norm.weight                 | size   4096           | type F32  | T+  38\n",
            "[242/291] Writing tensor blk.26.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  38\n",
            "[243/291] Writing tensor blk.26.attn_output.weight              | size   4096 x   4096  | type F16  | T+  38\n",
            "[244/291] Writing tensor blk.26.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  38\n",
            "[245/291] Writing tensor blk.26.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  38\n",
            "[246/291] Writing tensor blk.27.attn_norm.weight                | size   4096           | type F32  | T+  38\n",
            "[247/291] Writing tensor blk.27.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  38\n",
            "[248/291] Writing tensor blk.27.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  40\n",
            "[249/291] Writing tensor blk.27.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  40\n",
            "[250/291] Writing tensor blk.27.ffn_norm.weight                 | size   4096           | type F32  | T+  41\n",
            "[251/291] Writing tensor blk.27.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  41\n",
            "[252/291] Writing tensor blk.27.attn_output.weight              | size   4096 x   4096  | type F16  | T+  41\n",
            "[253/291] Writing tensor blk.27.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  41\n",
            "[254/291] Writing tensor blk.27.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  41\n",
            "[255/291] Writing tensor blk.28.attn_norm.weight                | size   4096           | type F32  | T+  41\n",
            "[256/291] Writing tensor blk.28.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  41\n",
            "[257/291] Writing tensor blk.28.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  42\n",
            "[258/291] Writing tensor blk.28.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  42\n",
            "[259/291] Writing tensor blk.28.ffn_norm.weight                 | size   4096           | type F32  | T+  43\n",
            "[260/291] Writing tensor blk.28.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  43\n",
            "[261/291] Writing tensor blk.28.attn_output.weight              | size   4096 x   4096  | type F16  | T+  43\n",
            "[262/291] Writing tensor blk.28.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  43\n",
            "[263/291] Writing tensor blk.28.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  43\n",
            "[264/291] Writing tensor blk.29.attn_norm.weight                | size   4096           | type F32  | T+  43\n",
            "[265/291] Writing tensor blk.29.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  43\n",
            "[266/291] Writing tensor blk.29.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  44\n",
            "[267/291] Writing tensor blk.29.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  44\n",
            "[268/291] Writing tensor blk.29.ffn_norm.weight                 | size   4096           | type F32  | T+  45\n",
            "[269/291] Writing tensor blk.29.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  45\n",
            "[270/291] Writing tensor blk.29.attn_output.weight              | size   4096 x   4096  | type F16  | T+  45\n",
            "[271/291] Writing tensor blk.29.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  45\n",
            "[272/291] Writing tensor blk.29.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  45\n",
            "[273/291] Writing tensor blk.30.attn_norm.weight                | size   4096           | type F32  | T+  45\n",
            "[274/291] Writing tensor blk.30.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  45\n",
            "[275/291] Writing tensor blk.30.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  45\n",
            "[276/291] Writing tensor blk.30.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  46\n",
            "[277/291] Writing tensor blk.30.ffn_norm.weight                 | size   4096           | type F32  | T+  46\n",
            "[278/291] Writing tensor blk.30.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  46\n",
            "[279/291] Writing tensor blk.30.attn_output.weight              | size   4096 x   4096  | type F16  | T+  46\n",
            "[280/291] Writing tensor blk.30.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  46\n",
            "[281/291] Writing tensor blk.30.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  46\n",
            "[282/291] Writing tensor blk.31.attn_norm.weight                | size   4096           | type F32  | T+  46\n",
            "[283/291] Writing tensor blk.31.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  46\n",
            "[284/291] Writing tensor blk.31.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  47\n",
            "[285/291] Writing tensor blk.31.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  47\n",
            "[286/291] Writing tensor blk.31.ffn_norm.weight                 | size   4096           | type F32  | T+  48\n",
            "[287/291] Writing tensor blk.31.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  48\n",
            "[288/291] Writing tensor blk.31.attn_output.weight              | size   4096 x   4096  | type F16  | T+  48\n",
            "[289/291] Writing tensor blk.31.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  48\n",
            "[290/291] Writing tensor blk.31.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  48\n",
            "[291/291] Writing tensor output_norm.weight                     | size   4096           | type F32  | T+  48\n",
            "Wrote Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/mistral-7b-instruct-v0.1-txt-2-presto-sql.fp16.bin\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = MODEL_ID.split('/')[-1]\n",
        "\n",
        "# Convert to fp16\n",
        "fp16 = f\"{MODEL_NAME}/{MODEL_NAME.lower()}.fp16.bin\"\n",
        "!python llama.cpp/convert.py {MODEL_NAME} --outtype f16 --outfile {fp16}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI-j3NcCTjFQ"
      },
      "source": [
        "Perform the quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0puyruMuTlPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36cc159-25ff-4802-b28b-86f8233fdb64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "  Device 0: NVIDIA A100-SXM4-40GB, compute capability 8.0, VMM: yes\n",
            "main: build = 1759 (7bed7eb)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing 'Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/mistral-7b-instruct-v0.1-txt-2-presto-sql.fp16.bin' to 'Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/mistral-7b-instruct-v0.1-txt-2-presto-sql.Q4_0.gguf' as Q4_0\n",
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/mistral-7b-instruct-v0.1-txt-2-presto-sql.fp16.bin (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,58980]   = [\"▁ t\", \"i n\", \"e r\", \"▁ a\", \"h e...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "llama_model_quantize_internal: meta size = 1671744 bytes\n",
            "[   1/ 291]                    token_embd.weight - [ 4096, 32000,     1,     1], type =    f16, quantizing to q4_0 .. size =   250.00 MiB ->    70.31 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.076 0.096 0.111 0.121 0.111 0.096 0.076 0.056 0.039 0.025 0.021 \n",
            "[   2/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.056 0.038 0.024 0.020 \n",
            "[   4/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.121 0.113 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[   5/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[   6/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   7/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.035 0.010 0.014 0.020 0.027 0.037 0.051 0.084 0.477 0.084 0.051 0.037 0.027 0.020 0.014 0.013 \n",
            "[   8/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.014 0.022 0.035 0.052 0.074 0.098 0.120 0.129 0.119 0.098 0.074 0.052 0.035 0.022 0.018 \n",
            "[   9/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.035 0.010 0.013 0.017 0.022 0.030 0.041 0.066 0.563 0.065 0.042 0.030 0.022 0.017 0.013 0.014 \n",
            "[  10/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.035 0.010 0.015 0.022 0.033 0.050 0.082 0.154 0.229 0.154 0.082 0.050 0.033 0.022 0.015 0.014 \n",
            "[  11/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  13/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  14/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.055 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  15/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  16/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.035 0.011 0.017 0.026 0.038 0.054 0.072 0.092 0.341 0.091 0.073 0.054 0.038 0.026 0.017 0.015 \n",
            "[  17/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  18/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.035 0.011 0.018 0.027 0.039 0.055 0.073 0.088 0.338 0.088 0.073 0.055 0.039 0.027 0.018 0.015 \n",
            "[  19/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.012 0.019 0.028 0.041 0.055 0.072 0.120 0.264 0.120 0.072 0.055 0.041 0.029 0.019 0.017 \n",
            "[  20/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  21/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  22/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  23/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[  24/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.121 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  25/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.116 0.124 0.115 0.097 0.075 0.054 0.037 0.024 0.020 \n",
            "[  26/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[  29/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.119 0.112 0.097 0.076 0.056 0.038 0.025 0.021 \n",
            "[  30/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  31/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.053 0.074 0.097 0.118 0.129 0.118 0.097 0.074 0.053 0.036 0.023 0.019 \n",
            "[  32/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[  33/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.116 0.125 0.116 0.097 0.075 0.054 0.037 0.024 0.020 \n",
            "[  34/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.052 0.074 0.097 0.118 0.130 0.118 0.097 0.074 0.053 0.036 0.023 0.019 \n",
            "[  35/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.119 0.112 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[  38/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.119 0.112 0.097 0.076 0.056 0.038 0.025 0.021 \n",
            "[  39/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  40/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.053 0.075 0.098 0.117 0.125 0.117 0.098 0.075 0.054 0.036 0.023 0.019 \n",
            "[  41/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.096 0.111 0.117 0.111 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[  42/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  43/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.075 0.097 0.114 0.123 0.114 0.096 0.076 0.055 0.038 0.024 0.020 \n",
            "[  44/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.020 \n",
            "[  47/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  48/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  49/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.121 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  50/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.111 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[  51/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  52/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.075 0.096 0.114 0.124 0.114 0.097 0.075 0.055 0.038 0.024 0.020 \n",
            "[  53/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[  56/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  57/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  58/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.076 0.098 0.115 0.122 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[  59/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[  60/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.056 0.076 0.097 0.114 0.120 0.113 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  61/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.075 0.096 0.114 0.123 0.114 0.096 0.075 0.055 0.038 0.025 0.020 \n",
            "[  62/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  65/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  66/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  67/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.076 0.097 0.115 0.122 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[  68/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[  69/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  70/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.075 0.096 0.115 0.124 0.115 0.097 0.075 0.054 0.037 0.024 0.020 \n",
            "[  71/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[  74/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  75/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  76/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  77/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[  78/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.122 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  79/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.074 0.096 0.116 0.128 0.116 0.096 0.074 0.054 0.037 0.024 0.020 \n",
            "[  80/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.056 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.056 0.038 0.024 0.020 \n",
            "[  83/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  84/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  85/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.098 0.115 0.122 0.115 0.098 0.076 0.054 0.037 0.024 0.020 \n",
            "[  86/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.057 0.077 0.097 0.112 0.117 0.111 0.096 0.077 0.056 0.039 0.025 0.021 \n",
            "[  87/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  88/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.075 0.096 0.115 0.124 0.114 0.096 0.075 0.055 0.037 0.024 0.020 \n",
            "[  89/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.024 0.020 \n",
            "[  92/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  93/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  94/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.098 0.114 0.121 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[  95/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.057 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[  96/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[  97/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.116 0.126 0.116 0.097 0.075 0.054 0.037 0.024 0.020 \n",
            "[  98/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 100/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 101/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.076 0.098 0.115 0.123 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 103/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 104/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 105/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 106/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 107/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 108/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 109/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.115 0.125 0.115 0.097 0.075 0.054 0.037 0.024 0.020 \n",
            "[ 110/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 112/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 113/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 114/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 115/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.098 0.115 0.122 0.116 0.098 0.076 0.054 0.037 0.024 0.019 \n",
            "[ 116/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 117/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 118/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.053 0.074 0.097 0.117 0.128 0.117 0.097 0.074 0.053 0.036 0.023 0.019 \n",
            "[ 119/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.076 0.098 0.115 0.122 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 121/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 122/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 123/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 124/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.098 0.115 0.121 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 125/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.116 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 126/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 127/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.116 0.125 0.116 0.096 0.075 0.054 0.037 0.024 0.020 \n",
            "[ 128/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.076 0.098 0.115 0.123 0.115 0.098 0.076 0.054 0.037 0.024 0.020 \n",
            "[ 130/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 131/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 132/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 133/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.076 0.097 0.116 0.123 0.116 0.098 0.075 0.054 0.037 0.024 0.020 \n",
            "[ 134/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.112 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 135/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 136/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.054 0.075 0.097 0.117 0.128 0.116 0.097 0.074 0.054 0.036 0.023 0.019 \n",
            "[ 137/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 139/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 140/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 141/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 142/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.023 0.037 0.054 0.075 0.097 0.116 0.124 0.116 0.097 0.075 0.054 0.037 0.024 0.019 \n",
            "[ 143/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 144/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 145/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.053 0.075 0.097 0.117 0.127 0.117 0.097 0.075 0.054 0.036 0.023 0.019 \n",
            "[ 146/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 148/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 149/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 150/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 151/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.098 0.115 0.122 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 152/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 153/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.113 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 154/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.054 0.075 0.097 0.116 0.127 0.117 0.097 0.075 0.054 0.036 0.023 0.019 \n",
            "[ 155/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 157/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 158/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 159/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 160/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.023 0.037 0.054 0.076 0.098 0.116 0.123 0.116 0.098 0.076 0.054 0.037 0.023 0.020 \n",
            "[ 161/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 162/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 163/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.053 0.075 0.097 0.117 0.127 0.117 0.098 0.075 0.053 0.036 0.023 0.019 \n",
            "[ 164/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 166/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 167/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 168/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 169/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 170/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.096 0.111 0.117 0.111 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 171/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 172/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.035 0.053 0.074 0.098 0.118 0.129 0.118 0.097 0.074 0.053 0.036 0.023 0.019 \n",
            "[ 173/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 175/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[ 176/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[ 177/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 178/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.076 0.097 0.115 0.122 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 179/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.117 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 180/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 181/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.074 0.097 0.116 0.126 0.116 0.097 0.075 0.054 0.037 0.024 0.019 \n",
            "[ 182/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[ 184/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 185/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[ 186/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 187/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.115 0.123 0.115 0.098 0.076 0.054 0.037 0.024 0.020 \n",
            "[ 188/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.117 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 189/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 190/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.116 0.125 0.116 0.097 0.075 0.054 0.037 0.024 0.020 \n",
            "[ 191/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 193/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 194/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 195/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 196/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.098 0.115 0.123 0.115 0.098 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 197/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.037 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.117 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 198/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 199/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.116 0.126 0.116 0.097 0.075 0.054 0.036 0.023 0.020 \n",
            "[ 200/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.123 0.115 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 201/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.037 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.116 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 202/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 203/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.122 0.114 0.096 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 204/ 291]                        output.weight - [ 4096, 32000,     1,     1], type =    f16, quantizing to q6_K .. size =   250.00 MiB ->   102.54 MiB | hist: \n",
            "[ 205/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 206/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 207/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 208/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 211/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 212/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 213/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 214/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 215/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.024 0.037 0.054 0.076 0.098 0.116 0.123 0.115 0.098 0.075 0.054 0.037 0.024 0.020 \n",
            "[ 216/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.057 0.077 0.097 0.111 0.117 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 217/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 218/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.075 0.097 0.114 0.122 0.115 0.097 0.075 0.055 0.038 0.024 0.020 \n",
            "[ 219/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 220/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 221/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 222/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 223/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 224/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.098 0.115 0.123 0.115 0.098 0.076 0.055 0.037 0.024 0.019 \n",
            "[ 225/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.037 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.116 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 226/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.119 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[ 227/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.075 0.096 0.114 0.123 0.114 0.096 0.075 0.055 0.037 0.024 0.020 \n",
            "[ 228/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 229/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 230/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.111 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 231/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 232/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 233/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.024 0.037 0.054 0.076 0.098 0.115 0.123 0.115 0.097 0.076 0.054 0.037 0.024 0.020 \n",
            "[ 234/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.116 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 235/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.056 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.056 0.038 0.024 0.020 \n",
            "[ 236/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.075 0.097 0.115 0.123 0.115 0.097 0.075 0.055 0.037 0.024 0.020 \n",
            "[ 237/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 238/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 239/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 240/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 241/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 242/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.115 0.123 0.115 0.097 0.075 0.055 0.037 0.024 0.020 \n",
            "[ 243/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.037 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.116 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 244/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.120 0.113 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 245/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.075 0.097 0.114 0.124 0.115 0.097 0.075 0.055 0.037 0.024 0.020 \n",
            "[ 246/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 247/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 248/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.039 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 249/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 250/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 251/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 252/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.037 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.117 0.111 0.096 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 253/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 254/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 255/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 256/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 257/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 258/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 259/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 260/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.053 0.075 0.098 0.118 0.127 0.118 0.098 0.075 0.053 0.036 0.023 0.019 \n",
            "[ 261/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.037 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.117 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 262/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 263/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.024 0.037 0.054 0.075 0.097 0.116 0.126 0.116 0.097 0.075 0.054 0.037 0.024 0.020 \n",
            "[ 264/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 265/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.118 0.113 0.097 0.076 0.056 0.038 0.025 0.020 \n",
            "[ 266/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 267/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 268/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 269/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.053 0.075 0.097 0.118 0.127 0.117 0.098 0.075 0.053 0.036 0.023 0.019 \n",
            "[ 270/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.057 0.077 0.096 0.111 0.117 0.111 0.097 0.077 0.057 0.039 0.025 0.021 \n",
            "[ 271/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.115 0.122 0.115 0.097 0.075 0.055 0.037 0.024 0.020 \n",
            "[ 272/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.015 0.023 0.036 0.053 0.074 0.096 0.117 0.130 0.117 0.096 0.074 0.053 0.036 0.023 0.019 \n",
            "[ 273/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 274/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.024 0.037 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.037 0.024 0.020 \n",
            "[ 275/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.077 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.021 \n",
            "[ 276/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 277/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 278/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.054 0.075 0.097 0.117 0.125 0.116 0.098 0.075 0.054 0.037 0.023 0.019 \n",
            "[ 279/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.097 0.111 0.117 0.111 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 280/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.120 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 281/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.035 0.053 0.074 0.097 0.119 0.131 0.119 0.097 0.074 0.053 0.035 0.023 0.019 \n",
            "[ 282/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 283/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.014 0.023 0.035 0.053 0.075 0.098 0.118 0.127 0.118 0.098 0.075 0.053 0.035 0.023 0.019 \n",
            "[ 284/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.113 0.118 0.113 0.097 0.077 0.056 0.038 0.025 0.020 \n",
            "[ 285/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q4_0 .. size =   112.00 MiB ->    31.50 MiB | hist: 0.036 0.015 0.025 0.038 0.056 0.076 0.097 0.112 0.118 0.112 0.097 0.077 0.056 0.038 0.025 0.020 \n",
            "[ 286/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 287/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.023 0.036 0.054 0.075 0.097 0.117 0.126 0.117 0.097 0.075 0.054 0.036 0.023 0.019 \n",
            "[ 288/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.016 0.025 0.039 0.056 0.077 0.096 0.112 0.117 0.112 0.097 0.077 0.056 0.039 0.025 0.021 \n",
            "[ 289/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_0 .. size =    32.00 MiB ->     9.00 MiB | hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.114 0.121 0.114 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "[ 290/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q4_0 .. size =     8.00 MiB ->     2.25 MiB | hist: 0.036 0.014 0.022 0.035 0.052 0.074 0.098 0.119 0.130 0.119 0.098 0.074 0.052 0.035 0.023 0.019 \n",
            "[ 291/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "llama_model_quantize_internal: model size  = 13813.02 MB\n",
            "llama_model_quantize_internal: quant size  =  3917.87 MB\n",
            "llama_model_quantize_internal: hist: 0.036 0.015 0.024 0.038 0.055 0.076 0.097 0.113 0.122 0.113 0.097 0.076 0.055 0.038 0.024 0.020 \n",
            "\n",
            "main: quantize time = 13270.45 ms\n",
            "main:    total time = 13270.45 ms\n"
          ]
        }
      ],
      "source": [
        "# QUANTIZATION_METHODS = [\"q4_0\", \"q4_k_m\", \"q5_k_m\"]\n",
        "QUANTIZATION_METHODS = [\"q4_0\"]\n",
        "\n",
        "for method in QUANTIZATION_METHODS:\n",
        "    qtype = f\"{MODEL_NAME}/{MODEL_NAME.lower()}.{method.upper()}.gguf\"\n",
        "    !./llama.cpp/quantize {fp16} {qtype} {method}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t8XQI3STpOx"
      },
      "source": [
        "Run the model with llama.cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9DekwD4CTruF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e2f2f90-4312-47f6-cf92-6f32926d1ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log start\n",
            "main: build = 1759 (7bed7eb)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: seed  = 1704291202\n",
            "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "  Device 0: NVIDIA A100-SXM4-40GB, compute capability 8.0, VMM: yes\n",
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL/mistral-7b-instruct-v0.1-txt-2-presto-sql.Q4_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,58980]   = [\"▁ t\", \"i n\", \"e r\", \"▁ a\", \"h e...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 3.83 GiB (4.54 BPW) \n",
            "llm_load_print_meta: general.name     = .\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
            "llm_load_tensors: using CUDA for GPU acceleration\n",
            "llm_load_tensors: system memory used  =   70.42 MiB\n",
            "llm_load_tensors: VRAM used           = 3847.55 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init: VRAM kv self = 64.00 MB\n",
            "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_build_graph: non-view tensors processed: 676/676\n",
            "llama_new_context_with_model: compute buffer total size = 76.19 MiB\n",
            "llama_new_context_with_model: VRAM scratch buffer: 73.00 MiB\n",
            "llama_new_context_with_model: total VRAM used: 3984.56 MiB (model: 3847.55 MiB, context: 137.00 MiB)\n",
            "\n",
            "system_info: n_threads = 6 / 12 | AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
            "sampling: \n",
            "\trepeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty = 0.000\n",
            "\ttop_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.800\n",
            "\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n",
            "sampling order: \n",
            "CFG -> Penalties -> top_k -> tfs_z -> typical_p -> top_p -> min_p -> temp \n",
            "generate: n_ctx = 512, n_batch = 512, n_predict = 128, n_keep = 0\n",
            "\n",
            "\n",
            "\u001b[33m[INST] Write a SQL query or use a function to answer the following question. Use the SQL dialect Presto for AWS Athena.\n",
            "\n",
            "What is the average age of the dogs who have gone through any treatments? [/INST]\u001b[0m SELECT AVG(Dog_Age) FROM Dogs AS D1 JOIN Dog_Treatments AS DT1 ON D1.Dog_ID = DT1.Dog_ID GROUP BY DT1.Treatment [end of text]\n",
            "\n",
            "llama_print_timings:        load time =    1634.51 ms\n",
            "llama_print_timings:      sample time =      29.99 ms /    54 runs   (    0.56 ms per token,  1800.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     156.55 ms /    53 tokens (    2.95 ms per token,   338.55 tokens per second)\n",
            "llama_print_timings:        eval time =     455.41 ms /    53 runs   (    8.59 ms per token,   116.38 tokens per second)\n",
            "llama_print_timings:       total time =     661.18 ms\n",
            "Log end\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "model_list = [file for file in os.listdir(MODEL_NAME) if \"gguf\" in file]\n",
        "\n",
        "# prompt = input(\"Enter your prompt: \")\n",
        "# chosen_method = input(\"Name of the model (options: \" + \", \".join(model_list) + \"): \")\n",
        "\n",
        "chosen_method = model_list[0]\n",
        "\n",
        "# Verify the chosen method is in the list\n",
        "if chosen_method not in model_list:\n",
        "    print(\"Invalid name\")\n",
        "else:\n",
        "    qtype = f\"{MODEL_NAME}/{MODEL_NAME.lower()}.{method.upper()}.gguf\"\n",
        "    !./llama.cpp/main -m {qtype} -n 128 --color -ngl 35 -p \"{prompt}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ho08Cs9TuQw"
      },
      "source": [
        "Push the quantized model to Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "XeRYB8jBTwhc"
      },
      "outputs": [],
      "source": [
        "# Set the HuggingFace token as an environment variable\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "scTaxfwzTzCJ"
      },
      "outputs": [],
      "source": [
        "# !pip install huggingface-hub -qU\n",
        "\n",
        "# # I switched to this login method because the notebook_login() method\n",
        "# # below stopped working after a HuggingfaceHub update\n",
        "# !huggingface-cli login --token $HF_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EJm6jTXZT1hu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "9ae3c5b2c97b434e899aae8c1078d0ed",
            "ff90ccb1069e47fbb4d51a4693f5899d",
            "2b377ab4a76542d78bea3dbda1b50ce1",
            "02907ddfb8464af6a2e5a249927739b6",
            "fa762e047e2649428a27bb52104675da",
            "88023bffea0f4afebc23dbb2659dafbb",
            "f9ff02ee8e5b471bad823d1b27345ea3",
            "6d1bec321d9545c5a4139e72b7aa0929",
            "a590b5f7cc844e1ba1a53528c8a13a71",
            "a8b6d52f6ca34a87834e0bd4d1de7461",
            "898e2a7786f44e7691fcfe9e3ce845fb"
          ]
        },
        "outputId": "7b63e6c5-c4cc-4613-f375-c2eb187abc92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.1-txt-2-presto-sql.Q4_0.gguf:   0%|          | 0.00/4.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ae3c5b2c97b434e899aae8c1078d0ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/cnatale/Mistral-7B-Instruct-v0.1-Txt-2-Presto-SQL-lo-lora-GGUF/commit/9643b86cda9a3229a8b29dc30136628a7bb8824e', commit_message='Upload folder using huggingface_hub', commit_description='', oid='9643b86cda9a3229a8b29dc30136628a7bb8824e', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# !pip install -q huggingface_hub\n",
        "from huggingface_hub import create_repo, HfApi\n",
        "from google.colab import userdata\n",
        "\n",
        "# Defined in the secrets tab in Google Colab\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "api = HfApi()\n",
        "username = \"cnatale\"\n",
        "\n",
        "# Create empty repo for GGUF version of model\n",
        "create_repo(\n",
        "    repo_id = f\"{username}/{MODEL_NAME}-lo-lora-GGUF\",\n",
        "    repo_type=\"model\",\n",
        "    exist_ok=True,\n",
        "    token=hf_token\n",
        ")\n",
        "\n",
        "# Upload gguf files\n",
        "api.upload_folder(\n",
        "    folder_path=MODEL_NAME,\n",
        "    repo_id=f\"{username}/{MODEL_NAME}-lo-lora-GGUF\",\n",
        "    allow_patterns=f\"*.gguf\",\n",
        "    token=hf_token\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e70b1302aab144f7ab96fcb34971d12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_866b924c027a424cb80121a1b4f80492",
              "IPY_MODEL_d161ac90d05f4e5d919891792d0828ae",
              "IPY_MODEL_014c26b833bf4fa9ba3e7ee3c4e0019a"
            ],
            "layout": "IPY_MODEL_85554c32a6ff4a069738f24a211a6df0"
          }
        },
        "866b924c027a424cb80121a1b4f80492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09cd4ef57a4a4d91a204cd011a7f864f",
            "placeholder": "​",
            "style": "IPY_MODEL_61ee99a881c5442595642b74fd4ee422",
            "value": "config.json: 100%"
          }
        },
        "d161ac90d05f4e5d919891792d0828ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e938d2df461d4d2483e484f0a188a56e",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4927f0b8bf6e4525addeaceb8655646d",
            "value": 571
          }
        },
        "014c26b833bf4fa9ba3e7ee3c4e0019a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a76be851ab6474792f693eec0947918",
            "placeholder": "​",
            "style": "IPY_MODEL_9cec362568574caf8a5a8f001a9a3b30",
            "value": " 571/571 [00:00&lt;00:00, 50.8kB/s]"
          }
        },
        "85554c32a6ff4a069738f24a211a6df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09cd4ef57a4a4d91a204cd011a7f864f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ee99a881c5442595642b74fd4ee422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e938d2df461d4d2483e484f0a188a56e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4927f0b8bf6e4525addeaceb8655646d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a76be851ab6474792f693eec0947918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cec362568574caf8a5a8f001a9a3b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d2d211782c9457798449bb368e6c275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd12842e5dc14267a8ec87792634a1d3",
              "IPY_MODEL_134f5a2265db4db19d122d6d2c4ce724",
              "IPY_MODEL_189b6a15eafc4205ba8385bb79ff08a1"
            ],
            "layout": "IPY_MODEL_01ee37a1c72b4b688a955883559f2137"
          }
        },
        "cd12842e5dc14267a8ec87792634a1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eefba4a309654b72b3285720972de680",
            "placeholder": "​",
            "style": "IPY_MODEL_ad3f9f71803842dc9b4070680333d2e8",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "134f5a2265db4db19d122d6d2c4ce724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c289a1b73e46638b0ec8117d8ba1e3",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a1bdad953a24f00a2e7947101b53956",
            "value": 25125
          }
        },
        "189b6a15eafc4205ba8385bb79ff08a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a306d206c7642dc8e51d46f90b4f175",
            "placeholder": "​",
            "style": "IPY_MODEL_ce6b4663f37644608966321a26825cda",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 1.72MB/s]"
          }
        },
        "01ee37a1c72b4b688a955883559f2137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eefba4a309654b72b3285720972de680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3f9f71803842dc9b4070680333d2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97c289a1b73e46638b0ec8117d8ba1e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1bdad953a24f00a2e7947101b53956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a306d206c7642dc8e51d46f90b4f175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce6b4663f37644608966321a26825cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cab55a554934725b51fdb60c4c0b7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_311360687583488cb6e6f2413c1ae049",
              "IPY_MODEL_70764efc1bbe4e34add35c38233cad1c",
              "IPY_MODEL_905a803b0b8e44ba8c234c4e3aa1c780"
            ],
            "layout": "IPY_MODEL_938726d0e31243729fc2bc0f75604ec2"
          }
        },
        "311360687583488cb6e6f2413c1ae049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05f8620285c142a190506e04fc0dcb80",
            "placeholder": "​",
            "style": "IPY_MODEL_18aa55e8f37a482dbc43edb914797182",
            "value": "Downloading shards: 100%"
          }
        },
        "70764efc1bbe4e34add35c38233cad1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d818d0aeec4be49873338839241009",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab7b10ec23ff479ebb596f53fd73fa37",
            "value": 2
          }
        },
        "905a803b0b8e44ba8c234c4e3aa1c780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76316258bcea4be5ab7c10f38038dd16",
            "placeholder": "​",
            "style": "IPY_MODEL_d985ab4d975340949a8690356c1dc243",
            "value": " 2/2 [00:55&lt;00:00, 26.78s/it]"
          }
        },
        "938726d0e31243729fc2bc0f75604ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f8620285c142a190506e04fc0dcb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18aa55e8f37a482dbc43edb914797182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8d818d0aeec4be49873338839241009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7b10ec23ff479ebb596f53fd73fa37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76316258bcea4be5ab7c10f38038dd16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d985ab4d975340949a8690356c1dc243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d23defd27084214898658795be1f450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6b7ed0059654452be8bf5a8626778f0",
              "IPY_MODEL_2209a7f84d60462fb9fa1144acf8b8d2",
              "IPY_MODEL_077d0a67cb7b47e9be158aa38bbd6ee0"
            ],
            "layout": "IPY_MODEL_9a39311c15bc435d93b081e63aa39652"
          }
        },
        "b6b7ed0059654452be8bf5a8626778f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2f7da26c89d432b98f42c3426a6cc77",
            "placeholder": "​",
            "style": "IPY_MODEL_983358eefd614b0d9fd31239fef0a8bb",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "2209a7f84d60462fb9fa1144acf8b8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74cd52bd619f43ac8a9925d65db73972",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bbea4dddf424dce9073ac74a8aa8ec9",
            "value": 9942981696
          }
        },
        "077d0a67cb7b47e9be158aa38bbd6ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_976d97b691e840cfac5f2f3082b3bff6",
            "placeholder": "​",
            "style": "IPY_MODEL_07f2defc66904794862bfbc187b5523b",
            "value": " 9.94G/9.94G [00:31&lt;00:00, 308MB/s]"
          }
        },
        "9a39311c15bc435d93b081e63aa39652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f7da26c89d432b98f42c3426a6cc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "983358eefd614b0d9fd31239fef0a8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74cd52bd619f43ac8a9925d65db73972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbea4dddf424dce9073ac74a8aa8ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "976d97b691e840cfac5f2f3082b3bff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f2defc66904794862bfbc187b5523b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "265a6ad4eb3e4a3abcbace301fbfc34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbe824f72d884abdb76b1ea9830336f1",
              "IPY_MODEL_f98996c3b7f143ada87f131976729671",
              "IPY_MODEL_625725ccccbf40eca0ca19932fafab73"
            ],
            "layout": "IPY_MODEL_7c54081abe084e19a00ee2d27cb1263f"
          }
        },
        "cbe824f72d884abdb76b1ea9830336f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120621624ea24bd8ad90b4b61ca04996",
            "placeholder": "​",
            "style": "IPY_MODEL_23135116651a4837acbb7a6e7b695138",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "f98996c3b7f143ada87f131976729671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9071e09a0f894e51aaa10f13d48588b2",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b7c8f2aed004d31b522aefb98cd4908",
            "value": 4540516344
          }
        },
        "625725ccccbf40eca0ca19932fafab73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_800b05732b9641bcbc8f57b4a8482533",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2b239f554540538be74942753f68cb",
            "value": " 4.54G/4.54G [00:20&lt;00:00, 266MB/s]"
          }
        },
        "7c54081abe084e19a00ee2d27cb1263f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120621624ea24bd8ad90b4b61ca04996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23135116651a4837acbb7a6e7b695138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9071e09a0f894e51aaa10f13d48588b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b7c8f2aed004d31b522aefb98cd4908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "800b05732b9641bcbc8f57b4a8482533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2b239f554540538be74942753f68cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50a7bea1ad494e0d8b6f07a9579714ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a653f8785e44991a026801552e05184",
              "IPY_MODEL_b949027763e74760ae404174555935ca",
              "IPY_MODEL_5380c19b9c5e40e58b148ed0285d2392"
            ],
            "layout": "IPY_MODEL_e1afdce4ce7b48e28b3e1f523013a0de"
          }
        },
        "4a653f8785e44991a026801552e05184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d53f2e53db1c483bac9e0a34474f8eee",
            "placeholder": "​",
            "style": "IPY_MODEL_187a28b3e7d7448188fb99d2e498557c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b949027763e74760ae404174555935ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90e27803643e4dfcb30a8fcd33b09fc0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38b316b3410543d68da6bb0b116c668e",
            "value": 2
          }
        },
        "5380c19b9c5e40e58b148ed0285d2392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c377a9f602464db43d1b77e8a15b93",
            "placeholder": "​",
            "style": "IPY_MODEL_0a5eb6383dd64cbd835a5f929ae2281f",
            "value": " 2/2 [00:07&lt;00:00,  3.35s/it]"
          }
        },
        "e1afdce4ce7b48e28b3e1f523013a0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53f2e53db1c483bac9e0a34474f8eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187a28b3e7d7448188fb99d2e498557c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90e27803643e4dfcb30a8fcd33b09fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b316b3410543d68da6bb0b116c668e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7c377a9f602464db43d1b77e8a15b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5eb6383dd64cbd835a5f929ae2281f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "021ebaef9442472ba194111a7ee3d5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c23975e7c26c428f898ea37620385115",
              "IPY_MODEL_030ede6922444f2792338d5ea7d61353",
              "IPY_MODEL_b152fe67d4c64b4bb44a73e2f7b60015"
            ],
            "layout": "IPY_MODEL_da58d221ad2a4abfa45cc939b5b172de"
          }
        },
        "c23975e7c26c428f898ea37620385115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f44a6c7ff92346bcaf94c3e86eef8b18",
            "placeholder": "​",
            "style": "IPY_MODEL_6115486214ef4ee5906edf66b71c4ea0",
            "value": "generation_config.json: 100%"
          }
        },
        "030ede6922444f2792338d5ea7d61353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552875444ea44269b6889f9dc2d6cfb1",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59ad2204d5d54a91b4854b3b2717ad81",
            "value": 116
          }
        },
        "b152fe67d4c64b4bb44a73e2f7b60015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_787509e5e266450284f7fc7b03789ef5",
            "placeholder": "​",
            "style": "IPY_MODEL_22091f7b2147426eadc10f37e476e1e9",
            "value": " 116/116 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "da58d221ad2a4abfa45cc939b5b172de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44a6c7ff92346bcaf94c3e86eef8b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6115486214ef4ee5906edf66b71c4ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "552875444ea44269b6889f9dc2d6cfb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ad2204d5d54a91b4854b3b2717ad81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "787509e5e266450284f7fc7b03789ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22091f7b2147426eadc10f37e476e1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c669614659d04c2894e824fd49961cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d204bb0312840d3928fb2f356b7b91a",
              "IPY_MODEL_2db7150b727c49a39c17e04b216301a4",
              "IPY_MODEL_7ab64ae1b91e4399b03a7cd00e9c5b1a"
            ],
            "layout": "IPY_MODEL_1599555d51ca47569e0d0429d49835d5"
          }
        },
        "8d204bb0312840d3928fb2f356b7b91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd526a33f4944edebe374a209dc46058",
            "placeholder": "​",
            "style": "IPY_MODEL_b5552b6f5d8b4c848a18a45e250d18e6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2db7150b727c49a39c17e04b216301a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320e6e8e37bf4a4099b1b29d7c9abc00",
            "max": 1467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ad24fcf04ea43cf92abb65122a50a9b",
            "value": 1467
          }
        },
        "7ab64ae1b91e4399b03a7cd00e9c5b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd075c4872bb46729042d9d8348aed44",
            "placeholder": "​",
            "style": "IPY_MODEL_b1744365faaa43e8b8b314e5eff92a3e",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 121kB/s]"
          }
        },
        "1599555d51ca47569e0d0429d49835d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd526a33f4944edebe374a209dc46058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5552b6f5d8b4c848a18a45e250d18e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "320e6e8e37bf4a4099b1b29d7c9abc00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad24fcf04ea43cf92abb65122a50a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd075c4872bb46729042d9d8348aed44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1744365faaa43e8b8b314e5eff92a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf27688620a409e96b3fc70e4333b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5338e56f80624d3ab68ae00688248ffa",
              "IPY_MODEL_7374d314be41468dbf7e4f2c5d1b4df4",
              "IPY_MODEL_190666a9dcbd49abad6b718d132c250e"
            ],
            "layout": "IPY_MODEL_a817134b3ee14bee8d7c24955eb45b8b"
          }
        },
        "5338e56f80624d3ab68ae00688248ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbec8cb9c50c4ce3b7bd2a341f8fe399",
            "placeholder": "​",
            "style": "IPY_MODEL_3324620a2adb4c3ba4e7424ce9379bd2",
            "value": "tokenizer.model: 100%"
          }
        },
        "7374d314be41468dbf7e4f2c5d1b4df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7d1f8d05b34e1dac861156dd8ed64c",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_540cf369d08a46ecbe7d691f9040fdfb",
            "value": 493443
          }
        },
        "190666a9dcbd49abad6b718d132c250e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6144cca3c24d6c96b0a086669a4bdc",
            "placeholder": "​",
            "style": "IPY_MODEL_9da8ac8bc08d4060b2c367c12f7e516b",
            "value": " 493k/493k [00:00&lt;00:00, 35.0MB/s]"
          }
        },
        "a817134b3ee14bee8d7c24955eb45b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbec8cb9c50c4ce3b7bd2a341f8fe399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3324620a2adb4c3ba4e7424ce9379bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f7d1f8d05b34e1dac861156dd8ed64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540cf369d08a46ecbe7d691f9040fdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b6144cca3c24d6c96b0a086669a4bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da8ac8bc08d4060b2c367c12f7e516b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "543d2a87aa6f4d8e980181bce1c16a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_848ec03bd6294447a1e36466c6ad789c",
              "IPY_MODEL_b35775c1be574210b9472fc345d0d664",
              "IPY_MODEL_03f62897007e4c0aa6e717d17e52bf4b"
            ],
            "layout": "IPY_MODEL_243e1b951a994f91983541355419f48d"
          }
        },
        "848ec03bd6294447a1e36466c6ad789c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b11cbf4af017404098a8846c4f79f0d1",
            "placeholder": "​",
            "style": "IPY_MODEL_a021fa1b81ca430fad820f2a4e08b710",
            "value": "tokenizer.json: 100%"
          }
        },
        "b35775c1be574210b9472fc345d0d664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c04c690f4a454051912631fc7804984d",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78d31f0488b740e9a8cad25b96fdbdbe",
            "value": 1795303
          }
        },
        "03f62897007e4c0aa6e717d17e52bf4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dda502f1258e4d3dbaf47cd99c30c537",
            "placeholder": "​",
            "style": "IPY_MODEL_35f7cee0dd2449aa9fc90a2bb217a75b",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 7.26MB/s]"
          }
        },
        "243e1b951a994f91983541355419f48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11cbf4af017404098a8846c4f79f0d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a021fa1b81ca430fad820f2a4e08b710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c04c690f4a454051912631fc7804984d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78d31f0488b740e9a8cad25b96fdbdbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dda502f1258e4d3dbaf47cd99c30c537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f7cee0dd2449aa9fc90a2bb217a75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "953540da952e438f9e4b850dc273a2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41ffc19e8560408fa1e3099a935dcc41",
              "IPY_MODEL_d1b32e95244947099eab436ef464fc1d",
              "IPY_MODEL_472b81b371504e1bb58701dc2f548de0"
            ],
            "layout": "IPY_MODEL_5b887f3ffef643b98070272f2d4b8027"
          }
        },
        "41ffc19e8560408fa1e3099a935dcc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e43cfa6f6f4b0db65287db96e93729",
            "placeholder": "​",
            "style": "IPY_MODEL_3a455bca1b1947f6916cef15251514b4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d1b32e95244947099eab436ef464fc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db2907ecb0fe4e8b9564b613879e0f4e",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb5b769fb705496db5c9a0bfd1e879a4",
            "value": 72
          }
        },
        "472b81b371504e1bb58701dc2f548de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_895ec8f38eb74ceb85ab6212c8db2d17",
            "placeholder": "​",
            "style": "IPY_MODEL_086facd8ce024efbae38543a66573a6e",
            "value": " 72.0/72.0 [00:00&lt;00:00, 5.99kB/s]"
          }
        },
        "5b887f3ffef643b98070272f2d4b8027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e43cfa6f6f4b0db65287db96e93729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a455bca1b1947f6916cef15251514b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db2907ecb0fe4e8b9564b613879e0f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5b769fb705496db5c9a0bfd1e879a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "895ec8f38eb74ceb85ab6212c8db2d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086facd8ce024efbae38543a66573a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "181683e6d38e4e0192520cc06cbdf62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_853a60025b3c492d9fef418633700a51",
              "IPY_MODEL_f687e7df7b83406cbe225d3428504277",
              "IPY_MODEL_d46e14d875f54077b575bad03fefb5ce"
            ],
            "layout": "IPY_MODEL_159de2582d0d4056b7fa0ae435e01c40"
          }
        },
        "853a60025b3c492d9fef418633700a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d84cef1bbb42b3b9cfede246c24069",
            "placeholder": "​",
            "style": "IPY_MODEL_cf139ff385de42c2a7504415b699cf06",
            "value": "Generating train split: "
          }
        },
        "f687e7df7b83406cbe225d3428504277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5b7f1c2f8a34f58a3c63e8d645de72a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e2bf65e77064b05b117fa51e86b3361",
            "value": 1
          }
        },
        "d46e14d875f54077b575bad03fefb5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8806ad1587495e9b75b0392c8e16e2",
            "placeholder": "​",
            "style": "IPY_MODEL_89d970868c8f4edcb90a54e853e99879",
            "value": " 53/0 [00:00&lt;00:00,  7.44 examples/s]"
          }
        },
        "159de2582d0d4056b7fa0ae435e01c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d84cef1bbb42b3b9cfede246c24069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf139ff385de42c2a7504415b699cf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5b7f1c2f8a34f58a3c63e8d645de72a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4e2bf65e77064b05b117fa51e86b3361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e8806ad1587495e9b75b0392c8e16e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d970868c8f4edcb90a54e853e99879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29e055fe95464b94b11a2069bfb238c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fd8d8de0ed840a481346d2741292871",
              "IPY_MODEL_b40a0bca20024a0ab977dfc4f142b06f",
              "IPY_MODEL_49eb3e296e88478d8ae7f52a95e83f66"
            ],
            "layout": "IPY_MODEL_91e47a895c214f6a960d0519644f2ca7"
          }
        },
        "0fd8d8de0ed840a481346d2741292871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebedcb910ecc4b2fae8d6afa60072374",
            "placeholder": "​",
            "style": "IPY_MODEL_e156eeb5033f41f3b8c149cc4134a673",
            "value": "Generating train split: "
          }
        },
        "b40a0bca20024a0ab977dfc4f142b06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d949f2871e4a78b23efb7582860810",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbea0d84ca0d4e9b89f979b6700ed56a",
            "value": 1
          }
        },
        "49eb3e296e88478d8ae7f52a95e83f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e45aa988330841449ebabf953142b0d3",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa645e791984f8f9691e30b122a1b37",
            "value": " 11/0 [00:00&lt;00:00, 264.21 examples/s]"
          }
        },
        "91e47a895c214f6a960d0519644f2ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebedcb910ecc4b2fae8d6afa60072374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e156eeb5033f41f3b8c149cc4134a673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21d949f2871e4a78b23efb7582860810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dbea0d84ca0d4e9b89f979b6700ed56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e45aa988330841449ebabf953142b0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa645e791984f8f9691e30b122a1b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e07c8ee05e4dbb845465f81354a0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cc85ddcb1cf4b7f8a521b659b3edafa",
              "IPY_MODEL_5b68382b43b9493e834e49b649306973",
              "IPY_MODEL_4a234f02255a444fa577eb9ce1448693"
            ],
            "layout": "IPY_MODEL_87ee67023e8748cd9b72597d97952273"
          }
        },
        "3cc85ddcb1cf4b7f8a521b659b3edafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe270cf7c394a9dbc0a7719d03e351d",
            "placeholder": "​",
            "style": "IPY_MODEL_930ce1f7c325475e8102bffdce731846",
            "value": "events.out.tfevents.1704290457.4f0560a2c54d.546.0: 100%"
          }
        },
        "5b68382b43b9493e834e49b649306973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e7c65d0d8f64a4d8090273ec08781c5",
            "max": 8532,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ed71ab49fa1425c853d81b4a4e9b74f",
            "value": 8532
          }
        },
        "4a234f02255a444fa577eb9ce1448693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fc67fb319274756aa2068f7ab7fb3f4",
            "placeholder": "​",
            "style": "IPY_MODEL_a993c04f5cc145f1b5fb07845e40c5d8",
            "value": " 8.53k/8.53k [00:00&lt;00:00, 29.6kB/s]"
          }
        },
        "87ee67023e8748cd9b72597d97952273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe270cf7c394a9dbc0a7719d03e351d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930ce1f7c325475e8102bffdce731846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e7c65d0d8f64a4d8090273ec08781c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed71ab49fa1425c853d81b4a4e9b74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fc67fb319274756aa2068f7ab7fb3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a993c04f5cc145f1b5fb07845e40c5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a49aaa3697764d0680c057d27b1a8ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d10d7f371e48b99b259e9da62e3ed4",
              "IPY_MODEL_0411e6dcd9cb4c69868861e2186e96c7",
              "IPY_MODEL_975d87c56d41432c8e1ce13353bf54be"
            ],
            "layout": "IPY_MODEL_2fc28c9ebae34f29b3da7c3100c7723d"
          }
        },
        "b5d10d7f371e48b99b259e9da62e3ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8bd5efa67da44cabc288f4574d8b2d1",
            "placeholder": "​",
            "style": "IPY_MODEL_1dfcdfb4cc804a499f00d80e95826160",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "0411e6dcd9cb4c69868861e2186e96c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27da06ddc80544638322d46db3be4b57",
            "max": 109069176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e1431a5df314bda84e087701a1723c5",
            "value": 109069176
          }
        },
        "975d87c56d41432c8e1ce13353bf54be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d195e8327f421db3d6cd6706a024c1",
            "placeholder": "​",
            "style": "IPY_MODEL_27b314c10859481e84f6fdc30567f61b",
            "value": " 109M/109M [00:11&lt;00:00, 12.3MB/s]"
          }
        },
        "2fc28c9ebae34f29b3da7c3100c7723d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8bd5efa67da44cabc288f4574d8b2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dfcdfb4cc804a499f00d80e95826160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27da06ddc80544638322d46db3be4b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e1431a5df314bda84e087701a1723c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39d195e8327f421db3d6cd6706a024c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b314c10859481e84f6fdc30567f61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea64fc1482244ddf80a29937e335daae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16b822fa526741e39acb1cb491fdfaad",
              "IPY_MODEL_d2c8f13c97c742b1953e7a28b22b15ea",
              "IPY_MODEL_b3cebafe39254a6cacd6003f5db18ab4"
            ],
            "layout": "IPY_MODEL_38eedbeac0dc47a8826b057b472f12ef"
          }
        },
        "16b822fa526741e39acb1cb491fdfaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc19405223854c7f9951fadf7fa12a67",
            "placeholder": "​",
            "style": "IPY_MODEL_f12c5442ba4e4fd5bd27b07f6de624db",
            "value": "Upload 3 LFS files: 100%"
          }
        },
        "d2c8f13c97c742b1953e7a28b22b15ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fbe888e126a4b78a0c78f462eca42ad",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_232d939324984400a31424658ae071f2",
            "value": 3
          }
        },
        "b3cebafe39254a6cacd6003f5db18ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_262dfb1016664afdba79945aee4756b4",
            "placeholder": "​",
            "style": "IPY_MODEL_a548e7ffdc3a430fb7bbce18ec0e56c9",
            "value": " 3/3 [00:11&lt;00:00, 11.77s/it]"
          }
        },
        "38eedbeac0dc47a8826b057b472f12ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc19405223854c7f9951fadf7fa12a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12c5442ba4e4fd5bd27b07f6de624db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fbe888e126a4b78a0c78f462eca42ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232d939324984400a31424658ae071f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "262dfb1016664afdba79945aee4756b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a548e7ffdc3a430fb7bbce18ec0e56c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b571bb8cfd8848d086e41c6bf305bf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4db84a5e41ed4812a36198d694a4707d",
              "IPY_MODEL_aad1958ca48f4f4ab524de70fde62789",
              "IPY_MODEL_47fa38ac51c6478290ca5cea27d17c65"
            ],
            "layout": "IPY_MODEL_ae6ffcc365c44dac923f1a5be4a3c4a0"
          }
        },
        "4db84a5e41ed4812a36198d694a4707d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f71cd9286b7492f9b7dc097bdcdf54f",
            "placeholder": "​",
            "style": "IPY_MODEL_1d1ad6c4193b45c7bbb75409754898bf",
            "value": "training_args.bin: 100%"
          }
        },
        "aad1958ca48f4f4ab524de70fde62789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f2f46148814368aaa10e125443be2e",
            "max": 4728,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f25daa9e246d44e1929070c3df3730d8",
            "value": 4728
          }
        },
        "47fa38ac51c6478290ca5cea27d17c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec70ebbea65b49c8b05b0beee9d007b3",
            "placeholder": "​",
            "style": "IPY_MODEL_6d6b7cc546a1409fb96326df24caab32",
            "value": " 4.73k/4.73k [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "ae6ffcc365c44dac923f1a5be4a3c4a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f71cd9286b7492f9b7dc097bdcdf54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1ad6c4193b45c7bbb75409754898bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3f2f46148814368aaa10e125443be2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f25daa9e246d44e1929070c3df3730d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec70ebbea65b49c8b05b0beee9d007b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6b7cc546a1409fb96326df24caab32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ef4f578d63a4b0b8782cd4a9f535747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb9ab1e399e74939b27fabe159b6a1b2",
              "IPY_MODEL_b867ef0510b54a0c8e2103073512a920",
              "IPY_MODEL_0975a4bc7a2743e7a8051c70f7b31846"
            ],
            "layout": "IPY_MODEL_262162a8baa8454488f916339ea078ab"
          }
        },
        "fb9ab1e399e74939b27fabe159b6a1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c39d1a610a4e94be5f3eed0725dfc2",
            "placeholder": "​",
            "style": "IPY_MODEL_fe062ed8025c48c38164c81034fbc6fb",
            "value": "Loading base model: 100%"
          }
        },
        "b867ef0510b54a0c8e2103073512a920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bb1f943883c408aa9f4ffe37d8906cd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8e5e952f0c0426d86c7234468910859",
            "value": 1
          }
        },
        "0975a4bc7a2743e7a8051c70f7b31846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb99994d85b340d8bbea0f84cb51ea01",
            "placeholder": "​",
            "style": "IPY_MODEL_e73264b4befb4edf95ab4423e750a5c8",
            "value": " 1/1 [00:11&lt;00:00, 11.22s/it]"
          }
        },
        "262162a8baa8454488f916339ea078ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c39d1a610a4e94be5f3eed0725dfc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe062ed8025c48c38164c81034fbc6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bb1f943883c408aa9f4ffe37d8906cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e5e952f0c0426d86c7234468910859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb99994d85b340d8bbea0f84cb51ea01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73264b4befb4edf95ab4423e750a5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c3f29780ba41cbb3f7f497b4952f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41ab6a43fd5941939a2c959cb9bf1cd5",
              "IPY_MODEL_8e92906148db4d448d7c5112b7dd3958",
              "IPY_MODEL_f671f11b26194d47b1ba9ba18ca7d0c2"
            ],
            "layout": "IPY_MODEL_4b241ed1acf9410db62166631c5601a1"
          }
        },
        "41ab6a43fd5941939a2c959cb9bf1cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d18fe4bfd9249c29a250dc59091a96d",
            "placeholder": "​",
            "style": "IPY_MODEL_f73cd88ac27d4d858ba1145cda318ea2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8e92906148db4d448d7c5112b7dd3958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1ea1914c664e0c948f1c06595a5ce4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d84e01a8f2a14518a1b86cd752519226",
            "value": 2
          }
        },
        "f671f11b26194d47b1ba9ba18ca7d0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1ddf035d2a4835a81904a70c5c4d28",
            "placeholder": "​",
            "style": "IPY_MODEL_261d7639991f44a9bbdfbef28aad7761",
            "value": " 2/2 [00:06&lt;00:00,  2.86s/it]"
          }
        },
        "4b241ed1acf9410db62166631c5601a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d18fe4bfd9249c29a250dc59091a96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f73cd88ac27d4d858ba1145cda318ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e1ea1914c664e0c948f1c06595a5ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84e01a8f2a14518a1b86cd752519226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf1ddf035d2a4835a81904a70c5c4d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261d7639991f44a9bbdfbef28aad7761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d03cfe9650b4d08b2234995a224065f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6606f2d293994f4a9e2fe8381b63d0d8",
              "IPY_MODEL_19ffd17804d647bfb1c0e292fb2264cf",
              "IPY_MODEL_8d8af8a695e94070bf502664c80289ed"
            ],
            "layout": "IPY_MODEL_4022d257ecc840b8a7afb69d4aeb306d"
          }
        },
        "6606f2d293994f4a9e2fe8381b63d0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6c3bc2ed5740139a191ee733af34da",
            "placeholder": "​",
            "style": "IPY_MODEL_583273e7bf3a4990a024e798d47c3a73",
            "value": "Loading Peft model: 100%"
          }
        },
        "19ffd17804d647bfb1c0e292fb2264cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a6f4d2bbfde48d59d449be12f77b586",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9216eb14a3ed4aada32327a3b6c5d878",
            "value": 1
          }
        },
        "8d8af8a695e94070bf502664c80289ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9e8f828d83e42dbb71f8be530f90056",
            "placeholder": "​",
            "style": "IPY_MODEL_e7ac850103774185a5629b58b86f9971",
            "value": " 1/1 [00:16&lt;00:00, 16.60s/it]"
          }
        },
        "4022d257ecc840b8a7afb69d4aeb306d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6c3bc2ed5740139a191ee733af34da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583273e7bf3a4990a024e798d47c3a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a6f4d2bbfde48d59d449be12f77b586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9216eb14a3ed4aada32327a3b6c5d878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9e8f828d83e42dbb71f8be530f90056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ac850103774185a5629b58b86f9971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6bb369c5afa49daa408f9ecfffdb4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15bd21c93a50479ba748dc5ea382c37f",
              "IPY_MODEL_1affa4a1f6c04e2d925f140ff36ed7db",
              "IPY_MODEL_a0058572a14c468eb65b1b92ea6213c8"
            ],
            "layout": "IPY_MODEL_a105d03a0e8f42d49148d877df8a0f2d"
          }
        },
        "15bd21c93a50479ba748dc5ea382c37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f562b2afee4630846166e05f366ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_b75bd2b58a5d4aa4bf772847c881a71a",
            "value": "adapter_config.json: 100%"
          }
        },
        "1affa4a1f6c04e2d925f140ff36ed7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1580136cd21444b1a83b9517271bf85e",
            "max": 586,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4763a628201a4388b55e2478b05b08b9",
            "value": 586
          }
        },
        "a0058572a14c468eb65b1b92ea6213c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec388726c99b4694bb031ffc3a0c951f",
            "placeholder": "​",
            "style": "IPY_MODEL_dabd8681922848c6bde4e8725a301f8c",
            "value": " 586/586 [00:00&lt;00:00, 51.6kB/s]"
          }
        },
        "a105d03a0e8f42d49148d877df8a0f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21f562b2afee4630846166e05f366ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b75bd2b58a5d4aa4bf772847c881a71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1580136cd21444b1a83b9517271bf85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4763a628201a4388b55e2478b05b08b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec388726c99b4694bb031ffc3a0c951f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabd8681922848c6bde4e8725a301f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c533aa7e8f4202b9e88ce1b68c5ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_911b9a0a542146f3a3cdff88be9ab6ca",
              "IPY_MODEL_456b7cfab2cd4bd8b4cacc768daf09e3",
              "IPY_MODEL_521ecda57031431683b05dd4ec1ad5b9"
            ],
            "layout": "IPY_MODEL_17865eb9b809416187bec7d7755a0cba"
          }
        },
        "911b9a0a542146f3a3cdff88be9ab6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6be1a38d85d4ebbac8b818cb8c0f82a",
            "placeholder": "​",
            "style": "IPY_MODEL_efa45522a8ae43e591374869006fdd0a",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "456b7cfab2cd4bd8b4cacc768daf09e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9f310eaecc409d8948539aab6bc2e0",
            "max": 109069176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f8aa41233014eb496d5267bbc43f9d5",
            "value": 109069176
          }
        },
        "521ecda57031431683b05dd4ec1ad5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78ea76317eac4430aaccb059d0d58211",
            "placeholder": "​",
            "style": "IPY_MODEL_4dc2de5d917642f2b527634e7b4d2c79",
            "value": " 109M/109M [00:04&lt;00:00, 24.1MB/s]"
          }
        },
        "17865eb9b809416187bec7d7755a0cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6be1a38d85d4ebbac8b818cb8c0f82a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa45522a8ae43e591374869006fdd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c9f310eaecc409d8948539aab6bc2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8aa41233014eb496d5267bbc43f9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78ea76317eac4430aaccb059d0d58211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc2de5d917642f2b527634e7b4d2c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c970f0c79b344ead9b60500b73654342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d5a5a6678d34d38a2839a6ec6d315b8",
              "IPY_MODEL_faa70417d49c4d53aafc132f509237f2",
              "IPY_MODEL_98d0106e8e3a451d965ca6befe638cea"
            ],
            "layout": "IPY_MODEL_f7dbc15907c74007a77b0557027d8bad"
          }
        },
        "6d5a5a6678d34d38a2839a6ec6d315b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cdf61dd3e264d17a7423e9e2aa5b0c1",
            "placeholder": "​",
            "style": "IPY_MODEL_1b17484016434046be6db68fe40dbc03",
            "value": "Merge and Unload: 100%"
          }
        },
        "faa70417d49c4d53aafc132f509237f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b86c8442d3645d095d578a89777c533",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd8a265df04746f88a4314e03119a5c2",
            "value": 1
          }
        },
        "98d0106e8e3a451d965ca6befe638cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f143cfabc21c4c1f9ef827dea04a708a",
            "placeholder": "​",
            "style": "IPY_MODEL_bd48abe89023498ca752332b18f683d2",
            "value": " 1/1 [00:00&lt;00:00, 22.62it/s]"
          }
        },
        "f7dbc15907c74007a77b0557027d8bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cdf61dd3e264d17a7423e9e2aa5b0c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b17484016434046be6db68fe40dbc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b86c8442d3645d095d578a89777c533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd8a265df04746f88a4314e03119a5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f143cfabc21c4c1f9ef827dea04a708a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd48abe89023498ca752332b18f683d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ae3c5b2c97b434e899aae8c1078d0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff90ccb1069e47fbb4d51a4693f5899d",
              "IPY_MODEL_2b377ab4a76542d78bea3dbda1b50ce1",
              "IPY_MODEL_02907ddfb8464af6a2e5a249927739b6"
            ],
            "layout": "IPY_MODEL_fa762e047e2649428a27bb52104675da"
          }
        },
        "ff90ccb1069e47fbb4d51a4693f5899d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88023bffea0f4afebc23dbb2659dafbb",
            "placeholder": "​",
            "style": "IPY_MODEL_f9ff02ee8e5b471bad823d1b27345ea3",
            "value": "mistral-7b-instruct-v0.1-txt-2-presto-sql.Q4_0.gguf: 100%"
          }
        },
        "2b377ab4a76542d78bea3dbda1b50ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1bec321d9545c5a4139e72b7aa0929",
            "max": 4109853248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a590b5f7cc844e1ba1a53528c8a13a71",
            "value": 4109853248
          }
        },
        "02907ddfb8464af6a2e5a249927739b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b6d52f6ca34a87834e0bd4d1de7461",
            "placeholder": "​",
            "style": "IPY_MODEL_898e2a7786f44e7691fcfe9e3ce845fb",
            "value": " 4.11G/4.11G [03:17&lt;00:00, 28.7MB/s]"
          }
        },
        "fa762e047e2649428a27bb52104675da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88023bffea0f4afebc23dbb2659dafbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ff02ee8e5b471bad823d1b27345ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d1bec321d9545c5a4139e72b7aa0929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a590b5f7cc844e1ba1a53528c8a13a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8b6d52f6ca34a87834e0bd4d1de7461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898e2a7786f44e7691fcfe9e3ce845fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}